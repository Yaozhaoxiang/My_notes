## 1. wxg 一面

1.https和http区别，加密怎么做
2.左值引用和右值引用
3.讲讲知道的c++新特性
4.互斥锁、自旋锁、还知道哪些锁
5.内存泄漏怎么检测
6.mysql和redis都是关系型数据库吗
7.redis为什么快
8.mysql索引底层数据结构，为什么用b+树
9.http位于7层模型哪一层，讲讲tcp三次握手
10.分布式redis用过吗
11.线程间通信方式
12.qps测试工具了解哪些

#### 12.qps测试工具了解哪些

QPS（Queries Per Second）即每秒查询率，是衡量系统性能的一个重要指标。以下为你介绍几种常用的 QPS 测试工具：

ab（Apache Benchmark）
+ 简介：ab 是 Apache HTTP 服务器自带的一个简单的性能测试工具，用于对 HTTP 服务进行基准测试。
+ 特点
    + 简单快速：使用方便，只需一个命令即可开始测试，能快速得到基本的性能指标。
    + 轻量级：对系统资源的消耗较小，适合在资源有限的环境中进行简单的性能测试。
+ 使用场景：适合对 HTTP 服务进行初步的性能评估，快速了解服务器的基本处理能力。


## 2. 后台开发

1. 在 MySQL 中，普通索引、唯一索引和主键索引对 NULL 值的支持情况各不相同:
2. sql数组分组用什么命令？group by, join, order by, limit 的优先级
3. 进程，线程，协程区别？一个进程能开多少个协程？
4. c++有没有Gc垃圾回收
5. 内存泄漏？怎么检测？如果开发阶段没有问题，但是运行的时候内存泄漏怎么排查定位？
> 6. 输入url发生什么？
> 7. 分布式锁怎么实现的?分布式锁有效性怎么保证?
> 8. HashMap怎么处理哈希冲突?
9. 三次握手?为什么需要三次握手
10. https和http区别，加密怎么做
11. 死锁检测
12. 十亿个数,找前100个,用什么算法,时间复杂度?
13. 大数相除，保留两位
14. 一个包到网卡以后,操作系统怎么处理?这个包怎么被上层应用接收到?
15. IO多路复用,select,epoll优缺点,两种模式 ET,LT
16. TCP全连接队列,半连接队列?
17. TCP流量控制，拥塞控制
18. TCP四次握手能不能简化为三次?
19. 怎么查服务器建立了多少个TCP连接?
20. 服务器TIME_WATE状态过多会对你的服务器产生什么影响?有什么办法能减少这种影响?
21. TCP建立连接,断开连接,中间会发送什么样的报文,客户端服务器分别处于什么状态?

22. vector的resize和reshape有什么区别
23. vector是分配在堆还是栈,sizeof(vector)返回什么值?
24. unordered_map中插入一个元素,它原来的iterator还有效吗?
25. map中插入一个元素,它原来的iterater还有效吗?
26. share_ptr是不是线程安全的,为什么?
27. 把unique_ptr move到share_ptr会发送什么?
28. 系统调用是什么？为什么还要分为用户态和内核态？怎么从用户态切换到内核态？

> 29. 红黑树有什么优势?红和黑代表什么?
30. 堆内存泄露和栈内存泄漏?
31. MyISAM和Inodb的区别，和使用场
32. rm删除一个文件，但是文件系统体积未变，什么情况下会发生？rm一个文件，系统会发送什么操作？

33. 如何忧患一条慢sql
34. get和post区别
> 35. http和rpc区别
> 36. http和websocket区别

> 37. static变量的初始化和线程安全
> 38. C和C++函数调用方式,CPP相比c的调用有哪些?
> 39. c++内存分区,堆区能否多线程共享
> 40. 如果一个类内存很大,给别人使用这个类时,怎么要求只能把内存分配到堆区>
> 41. 一块内存如果还没有被初始化就被其他线程访问会有问题吗?
> 42. 怎么写一个悲观锁?
> 43. SQL注入
44. git merge 和 get rebase的区别
### 1. 在 MySQL 中，普通索引、唯一索引和主键索引对 NULL 值的支持情况各不相同:

普通索引是最基本的索引类型，它的作用仅仅是加快对数据的访问速度，不限制索引列的值是否唯一，也不限制是否为 NULL。所以，普通索引的字段可以为 NULL，而且可以有多个 NULL 值。

```sql
-- 创建一个名为 users 的表，并为 name 字段创建普通索引
CREATE TABLE users (
    id INT,
    name VARCHAR(50),
    age INT,
    -- 使用 INDEX 关键字创建普通索引
    INDEX idx_name (name)
);

-- 为已存在的 users 表的 age 字段创建普通索引
CREATE INDEX idx_age ON users (age);
```

唯一索引要求索引列的值必须唯一，但它允许有一个 NULL 值。这是因为在 SQL 标准里，NULL 代表未知值，两个 NULL 值被认为是不相等的，所以可以在唯一索引列中有多个 NULL 值。

```sql
-- 创建一个名为 employees 的表，并为 email 字段创建唯一索引
CREATE TABLE employees (
    id INT,
    email VARCHAR(100),
    salary DECIMAL(10, 2),
    -- 使用 UNIQUE INDEX 关键字创建唯一索引
    UNIQUE INDEX idx_email (email)
);

-- 为已存在的 employees 表的 salary 字段创建唯一索引
CREATE UNIQUE INDEX idx_salary ON employees (salary);
```

主键用于唯一标识表中的每一行记录，它不允许取 NULL 值。这是因为主键的主要作用是确保记录的唯一性和完整性，如果允许 NULL 值，就无法保证能唯一标识每一行数据。

```cpp
-- 创建一个名为 products 的表，并将 id 字段设置为主键
CREATE TABLE products (
    id INT PRIMARY KEY,
    product_name VARCHAR(200),
    price DECIMAL(10, 2)
);

-- 为已存在的表添加主键索引
ALTER TABLE existing_table ADD PRIMARY KEY (column_name);
```

### 2. sql数组分组用什么命令？group by, join, order by, limit 的优先级

在 SQL 中，若要对数组（一般是指表中的行数据集合）进行分组操作，主要使用 GROUP BY 子句。
GROUP BY 子句的作用 : GROUP BY 用于将结果集按照一个或多个列进行分组，结合聚合函数（如 SUM、COUNT、AVG、MAX、MIN 等）可以对每个分组进行统计计算。

总结一下，这些子句的执行顺序（优先级）为：JOIN > GROUP BY > ORDER BY > LIMIT 。

1. 首先执行 JOIN 操作，它会根据指定的连接条件将多个表组合成一个临时结果集。
2. 对 JOIN 操作后的临时结果集按照 GROUP BY 指定的列进行分组。分组后可以使用聚合函数对每个分组进行计算。例如：
3. ORDER BY 用于对分组后的结果集进行排序，可以按照一个或多个列进行升序（ASC，默认）或降序（DESC）排序。
4. LIMIT 用于限制查询结果返回的行数，通常在排序之后使用，以获取排序后结果集的前几行。
5. 


### 3. 进程，线程，协程区别？一个进程能开多少个协程？

1.  概念
+ 进程（Process）
    + 进程是程序在操作系统中的一次执行过程，是系统进行资源分配和调度的基本单位。每个进程都有自己独立的内存空间、系统资源（如文件描述符等）和执行上下文。例如，当你打开一个浏览器，操作系统就会为浏览器程序创建一个进程。
+ 线程（Thread）
    + 线程是进程中的一个执行单元，是 CPU 调度和分派的基本单位。一个进程可以包含多个线程，这些线程共享进程的内存空间和系统资源，但每个线程有自己独立的栈空间和程序计数器，用于保存线程的执行状态。比如在浏览器进程中，可以有负责渲染页面的线程、处理网络请求的线程等。 
+ 协程（Coroutine）
    + 协程是一种比线程更加轻量级的并发编程模型，也被称为用户态线程。它由程序自身控制调度，而不是由操作系统内核进行调度。协程可以在一个线程中实现多个任务的并发执行，通过在任务之间主动让出执行权，实现上下文的切换。例如，在 Python 中使用 asyncio 库就可以实现协程编程。

2. 资源开销
    + 进程：进程的创建和销毁需要操作系统进行大量的资源分配和回收操作，包括内存空间的分配、文件描述符的分配等，因此进程的创建和切换开销较大。
    + 线程：线程的创建和销毁开销相对较小，因为线程共享进程的资源，不需要重新分配大量的系统资源。但线程的切换仍然需要操作系统内核进行调度，会有一定的开销。
    + 协程：协程的创建和切换开销非常小，因为协程的调度是在用户态完成的，不需要操作系统内核的干预，只需要保存和恢复协程的上下文信息即可。

3. 并发性
    + 进程：进程之间可以实现真正的并行执行，因为不同的进程可以在不同的 CPU 核心上同时运行。但进程间的通信和同步比较复杂，需要使用特定的进程间通信（IPC）机制，如管道、消息队列、共享内存等。
    + 线程：线程之间也可以实现并行执行，前提是在多核 CPU 系统中，不同的线程可以分配到不同的 CPU 核心上运行。线程间的通信和同步相对简单，可以通过共享内存的方式进行数据交换，但需要注意线程安全问题。
    + 协程：协程在单个线程中实现并发执行，通过在协程之间主动让出执行权，实现多个任务的交替执行。协程之间的通信和同步更加简单，因为它们共享同一个线程的上下文。但协程只能实现并发，不能实现真正的并行（除非使用多线程结合协程）。

4. 调度方式
    + 进程：进程的调度由操作系统内核负责，操作系统根据进程的优先级、资源使用情况等因素进行调度。进程的切换需要进行上下文切换，包括保存和恢复进程的寄存器状态、内存映射等信息。
    + 线程：线程的调度也由操作系统内核负责，操作系统会根据线程的优先级和调度算法进行线程的切换。线程的切换同样需要进行上下文切换，但由于线程共享进程的资源，切换开销相对较小。
    + 协程：协程的调度由程序自身控制，在协程中可以通过 yield、await 等关键字主动让出执行权，将执行权交给其他协程。协程的切换只需要保存和恢复协程的栈信息，开销非常小。

一个进程能开多少个协程
一个进程能开启的协程数量没有一个固定的上限，它受到多种因素的影响：

1. 内存限制
虽然协程的内存开销相对较小，但大量的协程仍然会占用一定的内存空间。每个协程都需要保存自己的上下文信息（如栈信息），如果系统内存不足，就无法创建更多的协程。例如，在 Python 的 asyncio 中，每个协程都有自己的栈，当创建大量协程时，栈空间的占用会逐渐增加。

2. CPU 处理能力
虽然协程本身不会占用太多的 CPU 资源，但大量协程的调度和切换也会消耗一定的 CPU 时间。如果 CPU 处理能力有限，过多的协程会导致系统性能下降。例如，在单核 CPU 系统中，过多的协程会导致频繁的上下文切换，增加 CPU 的负担。

3. 操作系统限制
操作系统对进程的资源使用有一定的限制，如最大文件描述符数量、最大线程数等。虽然协程不直接受这些限制的影响，但如果协程需要使用系统资源（如网络连接、文件操作等），这些限制可能会间接影响协程的创建数量。

### 4. c++有没有Gc垃圾回收

C++11 引入了智能指针，包括 std::unique_ptr、std::shared_ptr 和 std::weak_ptr，它们可以自动管理动态分配的内存，避免手动管理内存带来的问题，在一定程度上起到了类似垃圾回收的作用。

第三方垃圾回收库
除了智能指针，也有一些第三方库可以为 C++ 提供垃圾回收功能，例如 Boehm-Demers-Weiser 保守式垃圾回收器（Boehm GC）。

Boehm GC (“贝姆吉西”)
Boehm GC 是一个广泛使用的 C 和 C++ 垃圾回收库，它可以自动检测和回收不再使用的内存。使用 Boehm GC 时，开发者不需要手动调用 new 和 delete，而是使用 GC 提供的内存分配函数。

```cpp
#include <iostream>
#include <gc/gc.h>

int main() {
    // 使用 Boehm GC 分配内存
    int* ptr = (int*)GC_MALLOC(sizeof(int));
    *ptr = 40;
    std::cout << *ptr << std::endl;
    // 不需要手动释放内存，Boehm GC 会自动回收
    return 0;
}
```

底层原理：

Boehm GC 采用的是保守式垃圾回收策略，这意味着它并不精确地知道哪些内存区域是指针，而是通过扫描内存中的值，猜测哪些可能是指针。与之相对的是精确式垃圾回收，精确式垃圾回收器明确知道哪些内存位置是指针。


1. 标记阶段

+ 根集合扫描：垃圾回收的第一步是确定根集合（Root Set），根集合包含了程序中直接可访问的对象，例如全局变量、栈上的变量等。Boehm GC 会从根集合开始，扫描这些根对象所指向的内存地址。
+ 指针猜测与标记：在扫描过程中，Boehm GC 会检查内存中的每个值，猜测它是否是一个指针。由于采用保守式策略，它会把所有可能是指针的值都当作指针处理。对于被认为是指针的值，它会标记该指针所指向的对象为 “存活” 状态。然后，递归地对这些存活对象所指向的其他对象进行同样的标记操作，直到所有可达对象都被标记。

2. 清除阶段
+ 遍历堆内存：标记阶段完成后，Boehm GC 会遍历整个堆内存，检查每个对象的标记状态。
+ 回收未标记对象：那些未被标记为 “存活” 的对象被认为是不可达对象，也就是垃圾对象。Boehm GC 会回收这些垃圾对象所占用的内存空间，将其标记为可用，以便后续的内存分配使用。

关键技术与机制
1. 内存分配
Boehm GC 有自己的内存分配器，当程序需要分配内存时，会调用 Boehm GC 的内存分配函数。它会从预先分配的内存池中分配内存给程序使用。如果内存池中的内存不足，它会向操作系统请求更多的内存。
2. 内存对齐与块管理
为了提高内存访问效率和便于管理，Boehm GC 会对内存进行对齐处理。它将堆内存划分为不同大小的块，每个块可以包含一个或多个对象。在标记和清除过程中，以块为单位进行操作，这样可以减少扫描的粒度，提高回收效率。


### 5. 内存泄漏？怎么检测？如果开发阶段没有问题，但是运行的时候内存泄漏怎么排查定位？

内存泄漏指的是程序在运行过程中，由于某些原因导致已经不再使用的内存没有被及时释放，从而使得可用内存逐渐减少。随着程序的持续运行，内存泄漏可能会导致系统性能下降，甚至引发程序崩溃。在像 C 和 C++ 这类需要手动管理内存的语言中，内存泄漏是比较常见的问题。

使用静态代码分析工具
+ 原理：静态代码分析工具会在不运行代码的情况下，对代码进行语法和语义分析，检查代码中可能存在的内存泄漏问题。
+ 工具示例：
    + Cppcheck：是一个开源的 C/C++ 静态代码分析工具，它可以检查代码中的内存泄漏、未初始化变量等问题。
    + PVS-Studio：商业的静态代码分析工具，功能强大，能够检测出多种复杂的内存泄漏情况。

运行阶段排查定位内存泄漏的方法：

1. 使用内存分析工具
+ Valgrind（适用于 Linux 系统）
    + 原理：Valgrind 是一个强大的内存调试和分析工具，它会在程序运行时对内存的使用情况进行监控。当程序进行内存分配和释放操作时，Valgrind 会记录相关信息，并在程序结束后生成详细的报告，指出可能存在的内存泄漏问题。
    + 使用示例：假设你有一个 C++ 程序 test.cpp，编译生成可执行文件 test 后，可以使用以下命令运行程序并进行内存分析：

```bash
valgrind --leak-check=full ./test
```

报告解读：Valgrind 的报告中会显示哪些内存块没有被正确释放，以及这些内存块是在哪个函数中分配的，帮助你定位问题代码。


> Cppcheck 的使用方法
> cppcheck file1.cpp file2.cpp file3.cpp
> 

### 6.输入url发生什么？

1. DNS 解析
+ 作用：URL 中的域名（如 www.example.com）是方便用户记忆的，但计算机网络通信需要使用 IP 地址。DNS（Domain Name System，域名系统）解析的目的就是将域名转换为对应的 IP 地址。
+ 过程
    + 浏览器缓存：浏览器会先检查自身的 DNS 缓存，看是否已经有该域名对应的 IP 地址。如果有且未过期，就直接使用该 IP 地址。
    + 操作系统缓存：若浏览器缓存中没有，浏览器会向操作系统查询其 DNS 缓存。不同操作系统有不同的 DNS 缓存机制，例如 Windows 可以通过 ipconfig /displaydns 命令查看。
    + 本地 DNS 服务器：如果操作系统缓存中也没有，请求会被发送到本地 DNS 服务器（通常由网络服务提供商提供）。本地 DNS 服务器会检查自己的缓存，如果有则返回结果；如果没有，它会进行递归或迭代查询。
    + 根 DNS 服务器等：本地 DNS 服务器会向根 DNS 服务器、顶级域名 DNS 服务器、权威 DNS 服务器依次查询，最终获取到域名对应的 IP 地址，并将结果返回给浏览器。


2. TCP 连接
+ 作用：HTTP 协议是基于 TCP（Transmission Control Protocol，传输控制协议）的，在进行 HTTP 数据传输之前，需要先建立 TCP 连接。TCP 提供可靠的、面向连接的通信，确保数据在传输过程中不会丢失、乱序。
+ 过程：使用三次握手来建立连接。
    + 客户端发送 SYN 包：客户端向服务器发送一个 SYN（Synchronize Sequence Numbers）包，包含客户端的初始序列号，表明请求建立连接。
    + 服务器发送 SYN + ACK 包：服务器收到 SYN 包后，向客户端发送一个 SYN + ACK 包，包含服务器的初始序列号和对客户端 SYN 包的确认号。
    + 客户端发送 ACK 包：客户端收到 SYN + ACK 包后，向服务器发送一个 ACK（Acknowledgment）包，包含对服务器 SYN 包的确认号，至此 TCP 连接建立成功。

3. HTTP 请求
+ 作用：在 TCP 连接建立后，浏览器会根据输入的 URL 构造 HTTP 请求消息，并发送给服务器。
+ 请求格式：HTTP 请求由请求行、请求头和请求体组成。
    + 请求行：包含请求方法（如 GET、POST 等）、请求的资源路径和 HTTP 版本，例如 GET /index.html HTTP/1.1。
    + 请求头：包含一些附加信息，如用户代理（浏览器类型和版本）、接受的文件类型、缓存控制等。
    + 请求体：对于 GET 请求，请求体通常为空；对于 POST 请求，请求体可以包含要提交的数据，如表单数据。


4. 服务器处理请求
+ 作用：服务器接收到 HTTP 请求后，会对请求进行解析和处理。
+ 过程
    + Web 服务器软件接收请求：常见的 Web 服务器软件有 Apache、Nginx 等，它们负责接收客户端的请求，并将请求转发给相应的应用程序。
    + 应用程序处理请求：服务器端的应用程序（如基于 PHP、Python 的 Django 或 Flask 框架等）会根据请求的内容进行逻辑处理，可能会查询数据库、调用其他服务等。
    + 生成响应：应用程序处理完请求后，会生成一个 HTTP 响应消息。

5. HTTP 响应
+ 作用：服务器将处理结果封装成 HTTP 响应消息，并通过已建立的 TCP 连接发送给客户端。
+ 响应格式：HTTP 响应由状态行、响应头和响应体组成。
    + 状态行：包含 HTTP 版本、状态码和状态消息，例如 HTTP/1.1 200 OK，表示请求成功。
    + 响应头：包含一些附加信息，如响应内容的类型、长度、缓存策略等。
    + 响应体：包含服务器返回的实际数据，如 HTML 页面、图片、JSON 数据等。

6. 浏览器解析渲染页面
+ 作用：浏览器接收到 HTTP 响应后，会根据响应内容进行解析和渲染，将页面呈现给用户。
+ 过程
    + 解析 HTML：浏览器会解析 HTML 文件，构建 DOM（Document Object Model，文档对象模型）树。    
    + 解析 CSS：同时解析 CSS 文件，构建 CSSOM（CSS Object Model，CSS 对象模型）树。
    + 合并渲染树：将 DOM 树和 CSSOM 树合并成渲染树，渲染树只包含需要显示的元素及其样式信息。
    + 布局和绘制：根据渲染树进行布局（确定元素的位置和大小）和绘制（将元素绘制到屏幕上），最终呈现出完整的页面。

7. TCP 连接关闭
+ 作用：当页面资源加载完成后，浏览器和服务器之间的 TCP 连接会关闭，释放系统资源。
+ 过程：使用四次挥手来关闭连接。
    + 客户端发送 FIN 包：客户端向服务器发送一个 FIN（Finish）包，表示请求关闭连接。
    + 服务器发送 ACK 包：服务器收到 FIN 包后，向客户端发送一个 ACK 包，表示确认收到关闭请求。
    + 服务器发送 FIN 包：服务器也向客户端发送一个 FIN 包，表示自己也请求关闭连接。
    + 客户端发送 ACK 包：客户端收到 FIN 包后，向服务器发送一个 ACK 包，表示确认收到服务器的关闭请求，至此 TCP 连接关闭。

### 7.分布式锁怎么实现的?分布式锁有效性怎么保证?

#### 1. 为什么要使用分布式锁

一种跨机器的互斥机制来控制共享资源的访问，这就是分布式锁要解决的问题！

### 2. 分布式锁的实现方式

1. 基于数据库实现
悲观锁实现
原理：利用数据库的行级锁或表级锁，在事务中对某一行或整个表加锁，确保同一时间只有一个事务可以对其进行操作，从而实现分布式锁。
```sql

```

乐观锁实现
原理：通过在表中添加版本号字段，在更新数据时检查版本号是否与查询时一致，如果一致则更新数据并更新版本号，否则表示数据已被其他事务修改，需要重试。
```sql
-- 创建带版本号的表
CREATE TABLE resource (
    id INT PRIMARY KEY,
    data VARCHAR(255),
    version INT DEFAULT 0
);

-- 获取锁（尝试更新版本号）
UPDATE resource
SET data = 'new_data', version = version + 1
WHERE id = 1 AND version = (SELECT version FROM resource WHERE id = 1);
```





### 8. std::unordered_map 和 std::map,怎么处理哈希冲突?

std::unordered_map 的实现（基于哈希表）

基本原理
std::unordered_map 使用哈希表来存储键值对。哈希表是一种根据键（key）直接访问内存存储位置的数据结构，它通过哈希函数将键映射到一个固定大小的数组中的某个位置，这个数组被称为哈希桶（bucket）。

实现步骤
+ 哈希函数：对于插入的每个键，哈希函数会计算出一个哈希值，这个哈希值通常是一个整数。
+ 桶索引计算：通过哈希值和桶的数量，计算出该键应该存储在哪个桶中。
+ 冲突处理：由于不同的键可能会产生相同的哈希值，即哈希冲突，需要使用某种方法来处理冲突。常见的冲突处理方法有链地址法（separate chaining）和开放地址法（open addressing），std::unordered_map 通常使用链地址法，即每个桶中存储一个链表或其他容器，当发生冲突时，将新的键值对插入到对应的链表中。

链地址法:实现
具体来说，哈希表是一个数组，每个数组元素（即哈希桶）指向一个链表，当插入一个键值对时，先通过哈希函数计算出对应的桶索引，然后将该键值对插入到该桶对应的链表中。扩容和缩容操作主要是为了保持哈希表的负载因子在一个合理的范围内，从而保证哈希表的性能。负载因子（Load Factor）定义为哈希表中元素的数量与桶的数量之比。
```cpp
#include <iostream>
#include <vector>
#include <list>
#include <functional>

// 自定义的简单unordered_map实现
template <typename Key, typename Value>
class MyUnorderedMap {
private:
    // 定义链表节点结构
    struct Node {
        Key key;
        Value value;
        Node(const Key& k, const Value& v) : key(k), value(v) {}
    };

    // 哈希表，使用向量存储链表
    std::vector<std::list<Node>> buckets;
    // 哈希表的大小
    size_t bucketCount;
    // 元素数量
    size_t size_;

    // 哈希函数
    std::hash<Key> hashFunction;

    // 获取桶索引
    size_t getBucketIndex(const Key& key) const {
        return hashFunction(key) % bucketCount;
    }

public:
    // 构造函数，初始化哈希表大小
    MyUnorderedMap(size_t numBuckets = 10) : bucketCount(numBuckets), size_(0) {
        buckets.resize(bucketCount);
    }

    // 插入键值对
    void insert(const Key& key, const Value& value) {
        size_t index = getBucketIndex(key);
        auto& bucket = buckets[index];
        for (auto& node : bucket) {
            if (node.key == key) {
                // 如果键已存在，更新值
                node.value = value;
                return;
            }
        }
        // 键不存在，插入新节点
        bucket.emplace_back(key, value);
        ++size_;
    }

    // 查找键对应的值
    bool find(const Key& key, Value& value) const {
        size_t index = getBucketIndex(key);
        const auto& bucket = buckets[index];
        for (const auto& node : bucket) {
            if (node.key == key) {
                value = node.value;
                return true;
            }
        }
        return false;
    }

    // 删除键值对
    bool erase(const Key& key) {
        size_t index = getBucketIndex(key);
        auto& bucket = buckets[index];
        for (auto it = bucket.begin(); it != bucket.end(); ++it) {
            if (it->key == key) {
                bucket.erase(it);
                --size_;
                return true;
            }
        }
        return false;
    }

    // 获取元素数量
    size_t size() const {
        return size_;
    }
};

// 测试代码
int main() {
    MyUnorderedMap<int, std::string> myMap;

    // 插入键值对
    myMap.insert(1, "apple");
    myMap.insert(2, "banana");
    myMap.insert(3, "cherry");

    // 查找键值对
    std::string value;
    if (myMap.find(2, value)) {
        std::cout << "Key 2: " << value << std::endl;
    } else {
        std::cout << "Key 2 not found." << std::endl;
    }

    // 删除键值对
    if (myMap.erase(3)) {
        std::cout << "Key 3 removed." << std::endl;
    } else {
        std::cout << "Key 3 not found." << std::endl;
    }

    return 0;
}
```


开放寻址法
原理
开放寻址法不使用额外的链表结构，当发生哈希冲突时，会在哈希表中寻找下一个可用的位置来存储冲突的键值对。寻找下一个位置的方式有多种，常见的有线性探测、二次探测和双重哈希等。

+ 线性探测：如果当前位置已经被占用，就依次检查下一个位置，直到找到一个空位置。例如，哈希函数计算出的位置为 i，如果该位置被占用，就检查 i + 1、i + 2 等位置。
+ 二次探测：探测的步长是二次方关系，如检查 i + 1²、i + 2²、i + 3² 等位置。
+ 双重哈希：使用两个不同的哈希函数，当发生冲突时，使用第二个哈希函数来计算下一个探测位置。

### 9. 三次握手?为什么需要三次握手

三次握手: 具体过程包括客户端向服务器发送 SYN 包，服务器回应 SYN + ACK 包，客户端再发送 ACK 包。

需要三次握手主要基于以下几个重要原因：

1. 确认双方的发送和接收能力
+ 客户端到服务器方向：在第一次握手时，客户端向服务器发送 SYN 包。服务器接收到这个包后，就能够确认客户端具备发送数据的能力。因为如果客户端没有发送能力，服务器是不可能收到 SYN 包的。
+ 服务器到客户端方向：第二次握手，服务器向客户端发送 SYN + ACK 包。客户端接收到该包后，能确认服务器既具备接收数据的能力（因为收到了客户端的 SYN 包并作出响应），又具备发送数据的能力（因为收到了服务器发来的 SYN + ACK 包）。
+ 客户端再次确认：第三次握手，客户端向服务器发送 ACK 包。服务器接收到这个包后，就可以确认客户端也具备接收数据的能力，因为客户端成功接收了服务器的 SYN + ACK 包并进行了响应。

2. 初始化序列号
+ TCP 协议在传输数据时，需要为每个字节的数据分配一个序列号，以确保数据的有序传输和可靠交付。在三次握手过程中，客户端和服务器会互相交换初始序列号（ISN）。
+ 第一次握手，客户端发送 SYN 包时会携带自己的初始序列号。服务器在第二次握手时，不仅发送 SYN 包携带自己的初始序列号，还会对客户端的初始序列号进行确认。最后，客户端在第三次握手时，会对服务器的初始序列号进行确认。这样双方就都明确了对方的初始序列号，为后续的数据传输做好准备。

3. 防止历史连接的初始化
+ 在网络环境中，可能会存在一些延迟的数据包。如果只进行两次握手，当客户端发送的第一个 SYN 包由于网络延迟等原因在连接关闭后才到达服务器时，服务器会误以为这是一个新的连接请求，从而建立一个错误的连接。
+ 而三次握手机制可以避免这种情况。当服务器收到延迟的 SYN 包并发送 SYN + ACK 包后，客户端会发现这个 SYN + ACK 包对应的并不是自己当前想要建立的连接（因为客户端知道自己当前发送的 SYN 包序列号等信息），于是会发送 RST 包拒绝这个连接，从而避免了历史连接的错误初始化。

### 10. https和http区别，加密怎么做

HTTP（超文本传输协议）和 HTTPS（超文本传输安全协议）主要有以下区别：

+ 安全性
    + HTTP：以明文形式传输数据，不提供加密机制，数据在传输过程中容易被窃取、篡改或监听，安全性较低。
    + HTTPS 是在 HTTP 的基础上加入了 SSL/TLS 协议，通过加密和身份验证机制来保证数据传输的安全性。它使用对称加密和非对称加密相结合的方式对数据进行加密，即使数据在传输过程中被截获，攻击者也无法轻易解密获取其中的内容。

> 明文形式传输数据，指的是数据在网络中传输时，没有经过任何加密处理，以原始的、可读的形式进行传送 。
>数据内容直观呈现：以用户登录网站为例，当用户在登录框输入账号 “testuser” 和密码 “123456”，若网站使用 HTTP 协议以明文形式传输数据，那么在网络传输过程中，数据就像写在明信片上的文字一样，直接以 “账号：testuser，密码：123456” 这样的形式进行传递。无论是网络中的路由器、交换机，还是中间存在的恶意攻击者，只要有能力截取这段数据，都能直接看到其中的内容。
> 传输过程无加密转换：在数据传输过程中，HTTP 协议不会对数据进行额外的编码或加密处理。

+ 端口号
    + HTTP： 使用80端口，建立明文连接，过程简单
    + HTTPS: 使用 443 端口，在建立连接前需要进行 SSL/TLS 握手，协商加密算法和密钥等，连接过程更为复杂。
+ 性能
    + 由于 HTTP 不需要进行加密和解密操作，数据传输过程相对简单，因此在性能上通常比 HTTPS 要快一些。尤其是在对数据传输速度要求较高的场景下，HTTP 的优势更为明显。
    + HTTPS 在建立连接时需要进行 SSL/TLS 握手，这个过程涉及到证书验证、密钥交换等操作，会消耗一定的时间和计算资源，导致连接建立的时间比 HTTP 长。
        + 在数据传输过程中，加密和解密操作也会增加 CPU 开销，对服务器和客户端的性能都有一定的影响。不过，随着硬件性能的提升和加密算法的优化，HTTPS 的性能瓶颈在逐渐减小。

+ 证书
    + HTTP：无需证书，网站部署成本较低。
    + HTTPS：需要向 CA（证书颁发机构）申请 SSL/TLS 证书，以验证服务器的身份。

+ 应用场景
    + HTTP：适用于对安全性要求不高的场景，如一些静态页面的访问、新闻资讯网站等。这些网站的数据通常不包含敏感信息，使用 HTTP 可以提供更快的访问速度。
    + HTTPS：适用于涉及敏感信息传输的场景，如网上银行、电子商务网站、在线支付平台等。在这些场景中，用户的个人信息和资金安全至关重要，必须使用 HTTPS 来保证数据的安全性。

加密怎么做的?
主要运用对称加密与非对称加密结合的方式来实现数据加密;

+ 对称加密与非对称加密基础概念
    + 对称加密：采用相同的密钥对数据进行加密和解密操作。其优点是加密和解密速度快，效率高；缺点是密钥的分发和管理存在安全风险，一旦密钥泄露，数据就会被破解。常见的对称加密算法有 AES（高级加密标准）、DES（数据加密标准）等。
    + 非对称加密：使用一对密钥，即公钥和私钥。公钥可以公开，任何人都能使用它对数据进行加密；而私钥只有所有者持有，用于对加密的数据进行解密。非对称加密的安全性较高，但加密和解密的速度相对较慢。常见的非对称加密算法有 RSA、ECC（椭圆曲线加密算法）等。

### 11. 死锁检测

#### 1. gdb

通过gdb查看堆栈的调用情况, thread apply all bt;
单独查看每个线程的堆栈调用情况。 使用：info threads -> thread 1 -> bt;

#### 2. Valgrind

1. 编译程序时需要加上调试信息，例如 g++ -g -pthread your_program.cpp -o your_program。
2. 使用 Helgrind 运行程序：valgrind --tool=helgrind ./your_program。
3. Helgrind 会输出详细的信息，指出可能存在的死锁和数据竞争问题。

#### 3. 利用core文件分析
Core文件是程序异常终止时的内存镜像，包含了程序崩溃时的许多有用信息，如调用栈、寄存器状态等。

ulimit -a

#### 使用GDB打开Core文件

当有了core文件和相应的可执行文件之后，使用以下命令来启动GDB：

gdb <path-to-executable> <path-to-core-file>

例如：

gdb /home/user/myprogram /home/user/core.1234

### 12. 十亿个数,找前100个,用什么算法,时间复杂度?

要从十亿个数中找出前 100 个最大（或最小）的数，可以使用堆排序算法，更具体地说是使用小顶堆（找前 100 个最大的数）或大顶堆（找前 100 个最小的数）。

算法步骤
1. 初始化小顶堆：从输入的十亿个数中先取出 100 个数，构建一个小顶堆。这个堆的大小为 100。

2. 遍历剩余的数：对剩下的数依次进行如下操作：
+ 将当前数与堆顶元素比较，如果当前数大于堆顶元素，说明当前数有可能是前 100 大的数。
+ 用当前数替换堆顶元素，然后对堆进行调整，使其重新满足小顶堆的性质。

3. 得到结果：遍历完所有数后，堆中的 100 个数就是前 100 个最大的数。

O(n logk)

### 13. 大数相除，保留两位

+ 实现大数相除并保留两位小数，可以使用字符串来表示大数，因为常规的数据类型（如 int、long）无法处理非常大的数。
+ 对于除法运算，通过模拟竖式除法的过程来实现。
+ 为了保留两位小数，需要在余数后面补零继续除，直到得到足够的小数位数。

```cpp
#include <iostream>
#include <string>

std::string bigNumberDivision(const std::string& num1, int num2) {
    std::string integerPart; // 整数
    int remainder = 0; // 上一步余数

    std::string decimalPart;  

    // 计算整数部分
    for (char digit : num1) {
        int temp = remainder * 10 + (digit - '0');
        integerPart += std::to_string(temp / num2);
        remainder = temp % num2;
    }

    // 去除整数部分的前导零
    while (integerPart.length() > 1 && integerPart[0] == '0') {
        integerPart.erase(0, 1);
    }

    // 计算小数部分
    for (int i = 0; i < 2; ++i) {
        remainder *= 10;
        decimalPart += std::to_string(remainder / num2);
        remainder = remainder % num2;
    }

    return integerPart + "." + decimalPart;
}

int main() {
    std::string num1 = "123";
    int num2 = 45;
    std::string result = bigNumberDivision(num1, num2);
    std::cout << result << std::endl;
    return 0;
}
```

时间复杂度：，其中  是 num1 的长度。主要时间开销在于遍历 num1 计算整数部分。
空间复杂度：，主要用于存储整数部分和小数部分的结果。

### 14. 一个包到网卡以后,操作系统怎么处理?这个包怎么被上层应用接收到?

应用层，负责给应用程序提供统一的接口；
表示层，负责把数据转换成兼容另一个系统能识别的格式；
会话层，负责建立、管理和终止表示层实体之间的通信会话；

传输层，负责端到端的数据传输；
网络层，负责数据的路由、转发、分片；

数据链路层，负责数据的封帧和差错检测，以及 MAC 寻址；
物理层，负责在物理网络中传输数据帧；

1. 网卡接收数据包

+ 物理层处理：网卡首先在物理层接收数据包的电信号或光信号，并将其转换为数字信号。网卡通过网线、光纤等物理介质与网络相连，当有数据传输过来时，网卡的物理接口会感知到信号变化，将其转换为二进制数据。
+ 链路层处理：网卡对接收的数据进行链路层的检查，比如检查帧头、帧尾、校验和等信息。如果校验和错误，说明数据包在传输过程中可能发生了损坏，网卡通常会丢弃该数据包。如果校验通过，网卡会将数据包从物理层传递给操作系统的网络驱动程序。

2. 操作系统内核处理

+ 网络驱动程序
    + 中断处理：当网卡接收到数据包后，会向 CPU 发送一个中断信号。CPU 响应中断，暂停当前正在执行的任务，转而执行网卡驱动程序的中断处理程序。中断处理程序的主要任务是从网卡的缓冲区中读取数据包，并将其传递给操作系统内核的网络协议栈。
    + 数据包封装：网络驱动程序会将接收到的数据包封装成适合内核处理的格式，添加一些必要的元数据，如数据包的来源、长度等信息。

+ 网络协议栈
    + 链路层处理：内核的网络协议栈首先对数据包进行链路层的处理，根据数据包的帧头信息，判断数据包的类型（如以太网帧、Wi - Fi 帧等），并提取出网络层的数据包（如 IP 数据包）。
    + 网络层处理：网络层负责处理 IP 数据包，检查 IP 地址、TTL（Time To Live）等信息。如果 TTL 为 0，说明数据包已经经过了太多的路由跳转，内核会丢弃该数据包并发送一个 ICMP（Internet Control Message Protocol）错误消息给发送方。如果 IP 地址是本地地址，内核会将数据包传递给传输层；如果是远程地址，内核会根据路由表选择合适的出口将数据包转发出去。
    + 传输层处理：传输层根据数据包的端口号和协议类型（如 TCP 或 UDP）对数据包进行进一步的处理。对于 TCP 数据包，内核会进行 TCP 连接的管理，如建立连接、数据传输、断开连接等操作。对于 UDP 数据包，内核会直接将其传递给相应的应用程序端口。

3. 数据包传递给上层应用程序
+ 套接字机制
    + 绑定端口：上层应用程序通过创建套接字（Socket）来与网络进行通信。应用程序在启动时会将套接字绑定到一个特定的端口上，告诉操作系统它要监听该端口的数据包。
    + 接收数据包：当内核的网络协议栈处理完数据包后，会根据数据包的端口号将其传递给相应的套接字。应用程序可以通过调用套接字的接收函数（如 recv() 或 recvfrom()）从套接字缓冲区中读取数据包，从而完成数据包从网卡到上层应用程序的传递过程。


### 15. IO多路复用,select,epoll优缺点,两种模式 ET,LT

IO 多路复用是一种让单个进程可以同时监听多个文件描述符（如套接字）的机制，当其中一个或多个文件描述符变为可读或可写状态时，进程能够得知并进行相应的处理。

select
+ 优点
    + 跨平台支持：select 是 POSIX 标准定义的函数，几乎在所有的类 Unix 系统上都能使用，具有很好的跨平台性。
    + 使用简单：select 的接口相对简单，只需要定义文件描述符集合，调用 select 函数等待文件描述符状态变化，然后检查集合中的文件描述符即可。

+ 缺点
    + 文件描述符数量限制：select 所能处理的文件描述符数量存在上限，一般是 1024（可以通过修改内核参数进行调整，但有一定难度），这在需要处理大量并发连接的场景下会成为瓶颈。
    + 线性扫描效率低：每次调用 select 后，需要遍历所有的文件描述符集合来检查哪些文件描述符的状态发生了变化，时间复杂度为 o(n)，当文件描述符数量较多时，效率会显著下降。
    + 数据拷贝开销大：select 使用的文件描述符集合是通过值传递的，每次调用 select 都需要将集合从用户空间拷贝到内核空间，在频繁调用的情况下，会带来较大的开销。

epoll
+ 优点
    + 支持大量文件描述符：epoll 没有文件描述符数量的限制，理论上可以处理的文件描述符数量只受限于系统的内存。
    + 事件驱动效率高：epoll 使用事件驱动的方式，当有文件描述符状态发生变化时，内核会主动通知用户进程，用户进程只需要处理发生变化的文件描述符，时间复杂度为 ，在处理大量并发连接时，性能远高于 select。
    + 减少数据拷贝：epoll 通过 epoll_ctl 函数注册文件描述符，内核会维护一个事件表，避免了每次调用都需要将文件描述符集合从用户空间拷贝到内核空间，减少了数据拷贝的开销。

+ 缺点
    + 跨平台性差：epoll 是 Linux 特有的机制，在其他操作系统上无法使用，这限制了其在跨平台开发中的应用。
    + 实现复杂：epoll 的接口相对复杂，需要理解 epoll_create、epoll_ctl 和 epoll_wait 等多个函数的使用，增加了开发的难度。

水平触发（LT）
原理
水平触发是一种比较传统的触发方式。当文件描述符（File Descriptor，简称 FD）上有可以进行 I/O 操作的条件满足时（例如，读缓冲区中有数据可读、写缓冲区有空闲空间可写），就会触发相应的事件。并且只要这个条件一直满足，每次调用 epoll_wait 等 I/O 多路复用函数时都会不断通知应用程序。






### 16. TCP全连接队列,半连接队列?

半连接队列和全连接队列是在服务器端处理客户端连接请求时非常重要的概念，它们用于管理不同阶段的 TCP 连接。

#### 半连接队列（SYN 队列）

概念
半连接队列，也称为 SYN 队列，是在 TCP 三次握手的第一个阶段使用的队列。当客户端向服务器发送 SYN 包请求建立连接时，服务器收到该 SYN 包后，会为这个连接分配必要的资源，并将这个连接信息放入半连接队列中，同时向客户端发送 SYN + ACK 包作为响应。此时这个连接处于半连接状态，因为还没有完成三次握手的最后一步。

工作流程
1. 客户端向服务器发送 SYN 包，请求建立 TCP 连接。
2. 服务器收到 SYN 包后，为该连接分配资源（如内存等），并将连接信息添加到半连接队列中。
3. 服务器向客户端发送 SYN + ACK 包。
4. 客户端收到 SYN + ACK 包后，发送 ACK 包给服务器，完成三次握手。如果客户端的 ACK 包正常5到达服务器，该连接会从半连接队列移除，并进入全连接队列。

影响因素
+ 队列长度限制：半连接队列有一定的长度限制，通常可以通过内核参数进行调整。如果半连接队列已满，服务器可能会丢弃新的 SYN 包，导致客户端连接失败。
+ SYN Flood 攻击：恶意攻击者可以利用半连接队列进行 SYN Flood 攻击，通过发送大量的 SYN 包但不发送 ACK 包，使半连接队列被占满，从而阻止正常客户端的连接请求。

#### 全连接队列（Accept 队列）

概念
全连接队列，也称为 Accept 队列，是在 TCP 三次握手完成后使用的队列。当服务器收到客户端的 ACK 包，完成三次握手后，连接进入全连接状态，服务器会将该连接从半连接队列移除，并将其放入全连接队列中。服务器的应用程序可以通过调用 accept() 系统调用从全连接队列中取出连接进行处理。

工作流程
1. 客户端发送 ACK 包完成三次握手。
2. 服务器将连接从半连接队列移除，并添加到全连接队列中。
3. 服务器的应用程序通过 accept() 系统调用从全连接队列中取出连接，开始进行数据传输。

影响因素
+ 队列长度限制：全连接队列同样有长度限制，也可以通过内核参数进行调整。如果全连接队列已满，服务器可能会忽略客户端的 ACK 包，客户端可能会重传 ACK 包，造成一定的延迟。
+ 应用程序处理能力：如果服务器的应用程序处理连接的速度较慢，全连接队列可能会被占满，影响新连接的建立。

### 17. TCP流量控制，拥塞控制

####  TCP 流量控制

概念
流量控制是一种端到端的机制，用于防止发送方发送数据的速度过快，导致接收方来不及处理而造成数据丢失。它主要通过接收方反馈的窗口大小信息来调节发送方的发送速率。

工作原理
+ 滑动窗口机制：TCP 使用滑动窗口协议来实现流量控制。接收方在 TCP 首部中通过 **窗口大小** 字段告知发送方自己当前可用的接收缓冲区大小。发送方根据这个窗口大小来决定可以发送多少数据。
+ 窗口动态调整：接收方会根据自身缓冲区的使用情况动态调整窗口大小。当接收方的缓冲区有更多空间时，会增大窗口大小，允许发送方发送更多数据；当缓冲区接近满时，会减小窗口大小，限制发送方的发送速率。

#### TCP 拥塞控制

概念
拥塞控制是一种全局性的机制，用于防止网络出现拥塞。当网络中的流量过大时，会导致数据包的延迟增加、丢失率上升，影响网络性能。拥塞控制通过**调节发送方的发送速率**，使网络中的流量保持在合理范围内。

主要算法和工作过程

拥塞窗口是发送方在进行 TCP 数据传输时使用的一个动态变量，它表示发送方在没有收到接收方确认（ACK）的情况下，最多可以发送的数据量（以字节或报文段为单位）。

+ 慢启动（Slow Start）
    + 原理：发送方初始时设置一个拥塞窗口（cwnd），大小通常为 1 个最大段大小（MSS）。每收到一个确认报文，拥塞窗口大小就增加 1 个 MSS。这样，发送方的发送速率会呈指数级增长。
    + 目的：快速探测网络的可用带宽。

+ 拥塞避免（Congestion Avoidance）
    + 原理：当拥塞窗口大小达到慢启动阈值（ssthresh）时，发送方进入拥塞避免阶段。在这个阶段，每收到一个确认报文，拥塞窗口大小只增加 1/cwnd 个 MSS，即拥塞窗口呈线性增长。
    + 目的：避免网络拥塞，使发送速率的增长更加平缓。

+ 快速重传（Fast Retransmit）
    + 原理：当发送方连续收到 3 个相同的确认报文时，说明有一个数据包可能丢失了，但网络并没有完全拥塞。此时，发送方会立即重传丢失的数据包，而不需要等待超时重传。
    + 目的：快速恢复丢失的数据包，减少等待超时的时间。

+ 快速恢复（Fast Recovery）
    + 原理：在快速重传之后，发送方进入快速恢复阶段。发送方将慢启动阈值（ssthresh）设置为当前拥塞窗口大小的一半，然后将拥塞窗口大小设置为 ssthresh + 3 * MSS（因为收到了 3 个重复确认）。之后，每收到一个重复确认，拥塞窗口大小增加 1 个 MSS。当收到新的确认报文时，将拥塞窗口大小设置为 ssthresh，进入拥塞避免阶段。
    + 目的：在网络没有完全拥塞的情况下，尽快恢复发送速率。

### 18 TCP四次握手能不能简化为三次?

在某些特定情况下，TCP 四次挥手可以简化为三次。

TCP 断开连接时使用四次挥手，其具体过程如下：
+ 客户端发送 FIN 包：客户端完成数据发送后，向服务器发送一个 FIN （Finish）包，表示请求关闭连接。此时客户端进入 FIN_WAIT_1 状态。
+ 服务器发送 ACK 包：服务器收到客户端的 FIN 包后，向客户端发送一个 ACK （Acknowledgment）包作为确认。服务器进入 CLOSE_WAIT 状态，客户端收到 ACK 包后进入 FIN_WAIT_2 状态。
+ 服务器发送 FIN 包：服务器完成数据发送后，向客户端发送一个 FIN 包，表示请求关闭连接。服务器进入 LAST_ACK 状态。
+ 客户端发送 ACK 包：客户端收到服务器的 FIN 包后，向服务器发送一个 ACK 包作为确认。客户端进入 TIME_WAIT 状态，服务器收到 ACK 包后关闭连接。

四次挥手可以简化为三次的情况:
在服务器收到客户端的 FIN 包后，如果服务器此时已经没有数据要发送，即可以立即关闭连接，那么服务器可以将 ACK 包和 FIN 包合并发送。这样原本的四次挥手就简化为三次：

+ 客户端发送 FIN 包：客户端向服务器发送 FIN 包，请求关闭连接，进入 FIN_WAIT_1 状态。
+ 服务器发送 ACK + FIN 包：服务器收到 FIN 包后，由于没有数据要发送，将 ACK 包和 FIN 包合并发送给客户端。服务器进入 LAST_ACK 状态，客户端收到该包后进入 CLOSING 或 TIME_WAIT 状态（取决于具体实现）。
+ 客户端发送 ACK 包：客户端向服务器发送 ACK 包作为确认，客户端进入 TIME_WAIT 状态，服务器收到 ACK 包后关闭连接。


简化的原因和条件
+ 原因：TCP 协议允许在一个 TCP 报文中同时设置多个标志位。当服务器没有数据要发送时，将 ACK 和 FIN 标志位同时设置在一个报文中发送，减少了一次报文传输，提高了连接关闭的效率。
+ 条件：服务器在收到客户端的 FIN 包时，必须已经完成了所有数据的发送，并且没有更多的数据需要发送给客户端。只有在这种情况下，服务器才能立即发送 FIN 包，从而实现将 ACK 包和 FIN 包合并发送。

### 19. 怎么查服务器建立了多少个TCP连接?

使用 netstat 命令

netstat 是一个常用的网络工具，可用于显示网络连接、路由表等信息。通过过滤 TCP 连接信息并统计数量，可以得到服务器建立的 TCP 连接数。

```bash
netstat -an | grep 'ESTABLISHED' | grep 'tcp' | wc -l
```

+ etstat -an：显示所有网络连接信息，包括 TCP 和 UDP 连接，-a 表示显示所有连接，-n 表示以数字形式显示地址和端口。
+ grep 'ESTABLISHED'：过滤出已建立（ESTABLISHED）状态的连接。
+ grep 'tcp'：进一步过滤出 TCP 连接。
+ wc -l：统计过滤后的行数，即 TCP 连接的数量。

### 20. 服务器TIME_WATE状态过多会对你的服务器产生什么影响?有什么办法能减少这种影响?

1. 占用系统资源
+ 端口资源：每个 TCP 连接需要使用一个源端口和一个目标端口，处于 TIME_WAIT 状态的连接会占用系统的端口资源。服务器可用的端口数量是有限的（通常为 1024 - 65535），如果 TIME_WAIT 状态的连接过多，会导致可用端口耗尽，从而无法建立新的连接。
+ 内存资源：操作系统需要为每个处于 TIME_WAIT 状态的连接维护一定的控制块信息，大量的 TIME_WAIT 连接会占用较多的内存资源，影响服务器的整体性能。

2. 增加 CPU 负担
+ 状态维护：操作系统需要对处于 TIME_WAIT 状态的连接进行状态维护和超时管理，频繁的状态检查和超时处理会增加 CPU 的负担，降低服务器的处理效率。

3. 影响新连接的建立
+ 端口复用受限：由于 TIME_WAIT 状态占用了大量端口，当有新的连接请求到来时，可能无法分配到可用的端口，导致新连接建立失败。

#### 减少 TIME_WAIT 状态影响的方法:

1. 调整内核参数
+ tcp_tw_reuse：该参数允许在 TIME_WAIT 状态的连接上复用端口。将其值设置为 1 可以开启此功能。
+ tcp_tw_recycle：该参数可以快速回收 TIME_WAIT 状态的连接。将其值设置为 1 可以开启此功能。

2. 优化应用程序设计
+ 长连接复用：尽量使用长连接代替短连接，减少频繁的连接建立和关闭操作，从而减少 TIME_WAIT 状态的产生。例如，在 HTTP 协议中，可以使用 Keep - Alive 机制来保持长连接。
+ 连接池技术：使用连接池来管理 TCP 连接，应用程序从连接池中获取和释放连接，而不是每次都建立新的连接，这样可以避免大量的 TIME_WAIT 状态。

### 21. TCP建立连接,断开连接,中间会发送什么样的报文,客户端服务器分别处于什么状态?

TCP 建立连接（三次握手）:

1. 第一次握手：客户端发送 SYN 报文
    + 发送的报文：客户端向服务器发送一个 SYN报文，该报文的 SYN 标志位被置为 1，表示请求建立连接。同时，客户端会随机选择一个初始序列号（ISN），假设为 client_isn，并将其放在报文的序列号字段中。
    + 客户端在发送 SYN 报文后，进入 SYN_SENT 状态，表示已发送连接请求，正在等待服务器的响应。
    + 服务器状态：服务器处于 LISTEN 状态，监听客户端的连接请求。

2. 第二次握手：服务器发送 SYN + ACK 报文
    + 发送的报文：服务器收到客户端的 SYN 报文后，会向客户端发送一个 SYN + ACK 报文。其中，SYN 标志位被置为 1，表示同意建立连接；ACK 标志位也被置为 1，表示对客户端 SYN 报文的确认。服务器也会随机选择一个初始序列号，假设为 server_isn，并将其放在报文的序列号字段中。同时，服务器会将客户端的初始序列号加 1（即 client_isn + 1）作为确认号，放在报文的确认号字段中，表示已收到客户端的 SYN 报文。
    + 客户端状态：仍然处于 SYN_SENT 状态，等待服务器的响应。
    + 服务器状态：在发送 SYN + ACK 报文后，进入 SYN_RCVD 状态，表示已收到客户端的连接请求并发送了响应，等待客户端的确认。

3. 第三次握手：客户端发送 ACK 报文

    + 发送的报文：客户端收到服务器的 SYN + ACK 报文后，会向服务器发送一个 ACK 报文。该报文的 ACK 标志位被置为 1，表示对服务器 SYN 报文的确认。客户端会将服务器的初始序列号加 1（即 server_isn + 1）作为确认号，放在报文的确认号字段中，表示已收到服务器的 SYN 报文。
    + 客户端状态：在发送 ACK 报文后，进入 ESTABLISHED 状态，表示连接已成功建立，可以开始进行数据传输。
    + 服务器状态：收到客户端的 ACK 报文后，也进入 ESTABLISHED 状态，表示连接已成功建立，可以开始进行数据传输。

### 22. vector的resize和reshape有什么区别

resize 函数的主要作用是改变 std::vector 容器中元素的数量。它会根据传入的参数对容器进行调整，可能会增加新元素，也可能会删除现有元素。

reserve 函数用于预先分配一定大小的内存空间，以避免在后续插入元素时频繁进行内存重新分配，从而提高插入操作的效率。它只影响容器的容量（即容器可以容纳的元素数量），而不改变容器中实际元素的数量。

### 23. vector是分配在堆还是栈,sizeof(vector)返回什么值?

std::vector 对象本身的分配位置取决于其定义方式，既可以分配在栈上，也可以分配在堆上。

```cpp
#include <iostream>
#include <vector>

int main() {
    std::vector<int> vec;  // vec 对象分配在栈上
    return 0;
}
```

vec 是一个局部变量，其内存是在栈上分配的。栈上的内存由编译器自动管理，当函数执行结束时，vec 对象会自动销毁。

```cpp
#include <iostream>
#include <vector>

int main() {
    std::vector<int>* vecPtr = new std::vector<int>();  // vecPtr 指向的对象分配在堆上
    delete vecPtr;  // 需要手动释放堆上的内存
    return 0;
}
```
当使用 new 操作符动态创建 std::vector 对象时，它会被分配在堆上

sizeof(std::vector) 返回的值
+ sizeof(std::vector) 返回的是 std::vector 对象本身的大小，而不是它所管理的元素占用的内存大小。std::vector 对象内部通常包含几个指针和一些其他的成员变量，用于管理元素的存储和状态。这些成员变量的具体内容和数量可能因编译器和实现而异，但一般来说，std::vector 对象包含指向元素存储区域的指针、当前元素数量和容量等信息。

在常见的 64 位系统上，sizeof(std::vector<int>) 通常返回 24 字节。这是因为 std::vector 对象可能包含三个指针（指向元素存储区域的起始位置、当前元素的末尾位置和容量的末尾位置），每个指针在 64 位系统上占用 8 字节。

需要注意的是，sizeof(std::vector) 不包括 std::vector 所管理的元素占用的内存大小。要获取 std::vector 中元素占用的总内存大小，可以使用 vec.size() * sizeof(T)，其中 vec 是 std::vector 对象，T 是 std::vector 存储的元素类型。

```cpp
    std::vector<int> vec = {1, 2, 3, 4, 5};
    std::cout << "Size of vector elements: " << vec.size() * sizeof(int) << std::endl;
```

### 24. unordered_map中插入一个元素,它原来的iterator还有效吗?

在 std::unordered_map 中插入一个元素后，原来的迭代器（iterator）是否有效取决于插入操作是否引发了哈希表的重新哈希（rehashing）。

当插入元素时，如果 std::unordered_map 的负载因子（load factor）没有超过其最大负载因子（max load factor），那么不会发生重新哈希。在这种情况下，原来的迭代器仍然有效。
负载因子的计算公式为：负载因子 = 元素数量 / 桶数量。当插入元素后负载因子超过最大负载因子时，std::unordered_map 会自动进行重新哈希，增加桶的数量以保持较低的负载因子，从而维持较好的查找性能。

插入操作引发重新哈希
当插入元素导致 std::unordered_map 的负载因子超过最大负载因子时，会发生重新哈希。重新哈希会重新分配桶的数量，并将所有元素重新插入到新的桶中。在这种情况下，原来的迭代器会失效。

+ 若插入元素未引发重新哈希，std::unordered_map 原来的迭代器仍然有效。
+ 若插入元素引发了重新哈希，std::unordered_map 原来的迭代器会失效。在进行插入操作后，如果不确定是否发生了重新哈希，不应该继续使用原来的迭代器，而应该重新获取有效的迭代器。

### 25. map中插入一个元素,它原来的iterater还有效吗?

在 C++ 的 std::map 中插入一个元素后，原来的迭代器（iterator）仍然有效.

底层实现原理
std::map 是基于红黑树（一种自平衡的二叉搜索树）实现的。红黑树具有以下特点：
+ 节点的有序性：红黑树中的节点按照键的大小进行排序，每个节点包含一个键值对，并且左子树中的所有节点的键都小于当前节点的键，右子树中的所有节点的键都大于当前节点的键。
+ 插入操作的特性：当在 std::map 中插入一个新元素时，红黑树会根据新元素的键的大小找到合适的位置插入新节点，并且在插入后会通过旋转和变色等操作来保持树的平衡。在这个过程中，除了新插入的节点和可能的一些节点的颜色或指针调整外，其他已存在的节点的内存地址不会发生改变。

由于迭代器本质上是指向红黑树中节点的指针或封装了指向节点的指针，而插入操作不会改变已存在节点的内存地址，所以原来的迭代器仍然指向有效的节点，即原来的迭代器仍然有效。

### 26. share_ptr是不是线程安全的,为什么?

std::shared_ptr 部分操作是线程安全的，但并非所有操作都具备线程安全性:

1. 引用计数操作的线程安全性
std::shared_ptr 的引用计数操作是线程安全的，这主要得益于标准库的实现采用了原子操作来管理引用计数。引用计数用于记录有多少个 std::shared_ptr 实例共享同一个对象，当引用计数变为 0 时，所管理的对象会被自动释放。

2. 非线程安全的操作
虽然引用计数操作是线程安全的，但 std::shared_ptr 的其他一些操作并非线程安全。

+ 对管理对象的访问
如果多个线程同时访问 std::shared_ptr 所管理的对象，并且其中至少有一个线程进行写操作，那么就会出现数据竞争问题，因为 std::shared_ptr 本身并不提供对所管理对象的并发访问保护。

```cpp
#include <iostream>
#include <memory>
#include <thread>

std::shared_ptr<int> sharedData = std::make_shared<int>(0);

void incrementData() {
    for (int i = 0; i < 10000; ++i) {
        ++(*sharedData); // 非线程安全的写操作
    }
}

int main() {
    std::thread t1(incrementData);
    std::thread t2(incrementData);

    t1.join();
    t2.join();

    std::cout << "Final value: " << *sharedData << std::endl;
    return 0;
}
```


### 27. 把unique_ptr move到share_ptr会发送什么?

std::unique_ptr 用于独占式地管理对象的生命周期，同一时间只能有一个 std::unique_ptr 指向某个对象；而 std::shared_ptr 则允许多个 std::shared_ptr 共享同一个对象的所有权，通过引用计数来管理对象的生命周期。当把 std::unique_ptr 移动（std::move）到 std::shared_ptr 时，会发生以下事情：

1. 所有权转移
+ std::unique_ptr 是独占所有权的智能指针，一旦使用 std::move 将其转移到 std::shared_ptr，std::unique_ptr 会失去对原对象的所有权，变为空指针（即 get() 方法返回 nullptr）。
+ std::shared_ptr 会接管该对象的所有权，并开始管理其生命周期。std::shared_ptr 会为这个对象维护一个引用计数，初始值为 1。


2. 引用计数机制启动
+ std::shared_ptr 内部使用引用计数来跟踪有多少个 std::shared_ptr 实例共享同一个对象。当 std::unique_ptr 转移到 std::shared_ptr 后，引用计数被初始化为 1。后续如果有其他 std::shared_ptr 拷贝或赋值这个 std::shared_ptr，引用计数会相应增加；当这些 std::shared_ptr 被销毁或重置时，引用计数会减少。当引用计数变为 0 时，对象会被自动删除

### 28. 系统调用是什么？为什么还要分为用户态和内核态？怎么从用户态切换到内核态？

1. 系统调用的定义

系统调用（System Call）是操作系统提供给用户程序调用的一组特殊接口，它是用户程序与操作系统内核进行交互的桥梁。用户程序通过系统调用请求操作系统提供的各种服务，如文件操作（打开、读写、关闭文件）、进程管理（创建、销毁进程）、内存管理（分配、释放内存）等。


2. 区分用户态和内核态的原因
+ 将操作系统的执行状态分为用户态（User Mode）和内核态（Kernel Mode）主要是出于安全性和稳定性的考虑，具体原因如下：
    + 保护操作系统内核：内核是操作系统的核心部分，负责管理系统的各种资源和硬件设备。如果用户程序可以随意访问内核数据和硬件资源，可能会导致系统崩溃或数据丢失。通过区分用户态和内核态，用户程序只能在用户态下运行，无法直接访问内核数据和硬件资源，必须通过系统调用请求内核提供服务，从而保护了内核的安全性和稳定性。

    + 资源隔离：不同的用户程序可能会相互竞争系统资源，如果没有有效的隔离机制，可能会导致资源冲突和数据混乱。用户态和内核态的分离可以实现资源的隔离，每个用户程序在自己的用户态空间中运行，只能访问自己的内存空间和被授权的资源，避免了不同程序之间的相互干扰。

    + 权限控制：内核态具有最高的权限，可以直接访问系统的所有资源和硬件设备；而用户态的权限较低，只能访问自己的内存空间和执行一些受限的操作。通过这种权限控制机制，可以确保系统的安全性和稳定性，防止用户程序进行非法操作。

3. 从用户态切换到内核态的方式
从用户态切换到内核态主要有以下三种方式：
+ 系统调用：这是最常见的方式。当用户程序需要操作系统提供服务时，会调用系统调用函数。在调用系统调用函数时，会触发一个软中断（例如，在 x86 架构下，使用 int 0x80 或 syscall 指令），将控制权从用户态转移到内核态。内核接收到系统调用请求后，会根据请求的类型执行相应的操作，并在操作完成后将结果返回给用户程序，然后再将控制权从内核态切换回用户态。

+ 异常：当用户程序在执行过程中发生异常（如除法错误、访问非法内存等）时，会触发一个异常处理程序。异常处理程序会将控制权从用户态转移到内核态，由内核来处理异常。内核会根据异常的类型采取相应的措施，如终止程序、修复错误等，处理完成后再将控制权切换回用户态。

+ 外部中断：当外部设备（如键盘、鼠标、硬盘等）需要与计算机进行交互时，会向 CPU 发送一个中断信号。CPU 接收到中断信号后，会暂停当前正在执行的用户程序，将控制权从用户态转移到内核态，执行相应的中断处理程序。中断处理程序会处理外部设备的请求，处理完成后再将控制权切换回用户态，继续执行被暂停的用户程序。


### 29. 红黑树有什么优势?红和黑代表什么?

#### 红黑树的优势

1. 高效的插入、删除和查找操作
    
    + 时间复杂度稳定：红黑树通过对节点进行着色和特定的平衡调整规则，确保树的高度始终保持在 O(log n)的范围内，其中 n 是树中节点的数量。这使得红黑树在插入、删除和查找操作上的时间复杂度都是 O(log n)，即使在最坏情况下也能保证高效的性能。相比普通的二叉搜索树，在极端情况下（如数据有序插入）可能会退化为链表，导致操作时间复杂度变为O(n) ，红黑树的稳定性优势明显。
    + 适合动态数据集：在需要频繁进行插入、删除操作的动态数据集中，红黑树能够快速地调整自身结构以保持平衡，从而保证操作的高效性。例如，在数据库索引、内存管理等场景中，数据会不断地进行插入和删除操作，红黑树可以很好地适应这种动态变化。

2. 相对简单的平衡调整
    + 操作复杂度低：与其他自平衡二叉搜索树（如 AVL 树）相比，红黑树的平衡调整操作相对简单。AVL 树在插入和删除节点后，需要通过频繁的旋转操作来保持树的严格平衡（左右子树高度差不超过 1），而红黑树只需要进行较少的旋转和节点颜色调整操作就能保证树的大致平衡，减少了平衡调整的开销。
    + 实现难度小：红黑树的平衡规则相对容易理解和实现，代码复杂度较低。这使得开发人员在实际应用中更容易使用红黑树来解决问题。

#### 红黑颜色的含义
红黑树中的节点被标记为红色或黑色，这些颜色并不是表示实际的物理属性，而是用于维护树的平衡。红黑树通过以下五条性质来保证树的大致平衡：
1. 每个节点要么是红色，要么是黑色：节点的颜色是红黑树平衡调整的基础，通过对节点颜色的调整来满足其他性质。
2. 根节点是黑色：根节点的颜色固定为黑色，这是红黑树的基本规则之一。
3. 每个叶子节点（NIL 节点，空节点）是黑色：在红黑树中，叶子节点是指那些空的节点，它们被视为黑色节点。
4. 如果一个节点是红色的，则它的两个子节点都是黑色的：这条性质避免了相邻的红色节点出现，保证了树中红色节点的分布相对均匀。
5. 对每个节点，从该节点到其所有后代叶子节点的简单路径上，均包含相同数目的黑色节点：这条性质保证了从根节点到任意叶子节点的路径上，黑色节点的数量是相同的，从而保证了树的大致平衡。



### 30. 堆内存泄露和栈内存泄漏?

栈内存是由操作系统自动管理的内存区域，用于存储函数的局部变量、参数和返回地址等。栈内存泄漏通常指的是由于栈溢出（Stack Overflow）导致的内存问题。栈溢出是指程序在使用栈内存时，超过了栈的最大容量，导致栈内存被耗尽。

产生原因
+ 递归调用过深：递归函数在每次调用时都会在栈上分配一定的内存空间，如果递归调用没有正确的终止条件或者终止条件设置不当，会导致递归调用过深，栈空间不断被占用，最终导致栈溢出。

+ 局部变量占用空间过大：在函数中定义了非常大的局部数组或结构体，可能会导致栈空间被迅速耗尽。例如：

调试器：如 GDB，可以在程序崩溃时查看栈信息，找出栈溢出的位置


### 31. MyISAM和Inodb的区别，和使用场

1. 事务支持
    + MyISAM：不支持事务。这意味着在使用 MyISAM 存储引擎时，无法保证一组操作的原子性、一致性、隔离性和持久性（ACID 特性）。例如，在一个包含多条 SQL 语句的操作序列中，如果其中一条语句执行失败，之前已经执行的语句所做的修改不会回滚，可能会导致数据不一致。
    + InnoDB：支持事务，遵循 ACID 特性。在进行一组操作时，如果其中一个操作失败，整个事务可以回滚到操作开始前的状态，保证了数据的完整性和一致性。例如，在一个银行转账的业务中，从一个账户扣款和向另一个账户入账这两个操作可以作为一个事务来处理，确保数据的正确性。

2. 外键约束
    + MyISAM：不支持外键约束。外键用于建立表与表之间的关联关系，保证数据的参照完整性。由于 MyISAM 不支持外键，在设计数据库时无法通过外键来强制表之间的数据一致性。
    + InnoDB：支持外键约束。可以通过定义外键来确保一个表中的数据与另一个表中的数据保持一致。例如，在订单表和客户表之间，可以通过外键将订单与对应的客户关联起来，当删除客户记录时，如果该客户还有未处理的订单，数据库可以根据外键约束进行相应的处理，如阻止删除或级联删除相关订单。

3. 锁机制
    + MyISAM：采用表级锁。当一个事务对表进行写操作（如插入、更新、删除）时，会锁定整个表，其他事务无法对该表进行读写操作。即使只是修改表中的一行数据，也会锁定整个表，这可能会导致并发性能较低，尤其是在高并发的写入场景下。
    + InnoDB：支持行级锁和表级锁，默认使用行级锁。行级锁可以只锁定需要操作的行，而不会锁定整个表，因此在并发操作时可以减少锁冲突，提高并发性能。多个事务可以同时对不同的行进行读写操作，从而提高系统的吞吐量。


4. 数据和索引存储方式
    + MyISAM：数据和索引是分开存储的。数据文件（.MYD）和索引文件（.MYI）是独立的文件，这种存储方式使得数据的备份和恢复相对简单，但在数据读取时可能需要更多的磁盘 I/O 操作。
    + InnoDB：数据和索引是存储在一起的，并且采用聚簇索引的方式。聚簇索引将数据行和对应的索引键存储在一起，这样在通过索引查找数据时可以直接定位到数据行，减少了磁盘 I/O 次数，提高了查询性能。

5. 崩溃恢复
    + MyISAM：不具备自动崩溃恢复能力。如果在使用 MyISAM 存储引擎时发生系统崩溃或意外断电等情况，可能会导致数据文件损坏，需要手动进行修复。
    + InnoDB：具有自动崩溃恢复能力。在系统崩溃或意外断电后，InnoDB 可以通过事务日志（redo log 和 undo log）来恢复到一致的状态，保证数据的完整性。

### 32. rm删除一个文件，但是文件系统体积未变，什么情况下会发生？rm一个文件，系统会发送什么操作？

1. 文件被进程占用
    + 当一个文件被某个进程打开并使用时，即便使用 rm 命令删除该文件，文件系统中的磁盘空间也不会立即释放，文件系统的体积也就不会改变。这是因为在 Linux 系统中，文件的删除是通过减少文件的硬链接数来实现的，只有当文件的硬链接数为 0 且没有任何进程再打开该文件时，文件所占用的磁盘空间才会被真正释放。
    + 例如，使用 tail -f 命令持续监控一个日志文件，此时对该日志文件执行 rm 操作，文件看似被删除，但实际上进程仍然持有对该文件的引用，磁盘空间不会被释放。

2. 文件系统缓存
文件系统会使用缓存来提高读写性能。当执行 rm 操作后，文件系统可能只是在逻辑上标记文件为已删除，而实际的磁盘空间释放操作可能会被延迟，直到缓存被刷新或者系统进行垃圾回收。在这个延迟期间，文件系统的体积看起来不会改变。


流程:
1. 权限检查
系统会首先检查执行 rm 命令的用户是否具有删除该文件的权限。这涉及到检查文件的权限位（读、写、执行权限）以及用户所属的用户组和文件的所有者等信息。如果用户没有足够的权限，rm 命令将失败并返回相应的错误信息。
2. 减少硬链接数
在 Linux 文件系统中，每个文件都有一个或多个硬链接。rm 命令会将文件的硬链接数减 1。如果硬链接数减为 0，并且没有任何进程打开该文件，那么文件所占用的磁盘空间将被标记为可重用。
3. 删除目录项
rm 命令会从文件所在的目录中删除该文件的目录项。目录项包含了文件的名称和对应的 inode 号码。删除目录项后，用户将无法再通过文件名访问该文件。
4. 释放 inode
当文件的硬链接数为 0 且没有进程打开该文件时，系统会释放该文件对应的 inode。inode 是文件系统中存储文件元数据（如文件大小、创建时间、权限等）的结构。
5. 标记磁盘块为可用
最后，系统会将文件所占用的磁盘块标记为可用，以便后续的文件可以使用这些磁盘空间。但如前面所述，这个操作可能会被延迟，直到文件系统缓存被刷新。

### 33. 如何忧患一条慢sql

1. 分析 SQL 语句

1.1 查看执行计划:
```sql
-- MySQL 示例
EXPLAIN SELECT * FROM users WHERE age > 20;
```

1.2 检查 SQL 语句逻辑
+ 避免全表扫描：尽量使用索引来过滤数据，避免使用 SELECT *，只选择需要的列，减少数据传输量。
+ 优化子查询：将子查询转换为连接查询，因为连接查询通常比子查询性能更好。


2. 索引优化
创建合适的索引
+ 单列索引：根据查询条件中的列创建单列索引，例如，如果经常根据 age 列进行查询，可以为 age 列创建索引。
+ 复合索引：当查询条件涉及多个列时，可以创建复合索引。复合索引的列顺序要根据查询条件的使用频率和选择性来确定。

3. 避免索引失效
+ 避免在索引列上使用函数或表达式：这样会导致索引无法使用。
+ 避免使用 OR 连接条件：如果 OR 连接的条件中有一个列没有索引，会导致整个索引失效。可以将 OR 条件拆分为多个查询，使用 UNION 连接。


### 34. get和post区别

1. 用途
+ GET
    + 通常用于获取资源。比如当你在浏览器地址栏输入一个网址并回车，浏览器就会发起一个 GET 请求来获取该网页的内容。再如访问搜索引擎搜索关键词时，也是使用 GET 请求将关键词发送给服务器以获取搜索结果页面。
+ POST
    + 主要用于向服务器提交数据，可能会导致服务器上的资源发生创建、更新等变化。例如在网页上填写表单（如注册表单、登录表单）后提交，一般会使用 POST 请求将表单数据发送给服务器进行处理。

2. 参数传递
+ GET
    + 参数会附加在 URL 的后面，以键值对的形式出现，多个参数之间用 & 符号连接。例如：https://example.com/search?keyword=apple&category=fruits。
    + 由于 URL 长度有限制（不同浏览器和服务器对 URL 长度的限制不同，一般限制在 2048 个字符左右），所以 GET 请求能携带的参数数量和大小都受到一定限制。
+ POST
    + 参数不会显示在 URL 中，而是放在请求体（body）里。请求体可以包含大量的数据，理论上对数据大小没有限制（实际受服务器配置限制），因此适合传递大量或敏感的数据，如文件上传就通常使用 POST 请求。

3. 安全性
+ GET
    + 因为参数暴露在 URL 中，所以安全性较低。例如在登录时使用 GET 请求传递用户名和密码，这些信息会直接显示在 URL 中，可能会被他人轻易获取，也容易被记录在浏览器历史记录、服务器日志中，存在信息泄露的风险。
    + 此外，GET 请求还容易受到 SQL 注入、跨站脚本攻击（XSS）等安全威胁，攻击者可以通过构造恶意的 URL 参数来执行非法操作。
+ POST
    + 参数放在请求体中，相对来说不那么容易被看到，一定程度上提高了数据的安全性。但这并不意味着 POST 请求就绝对安全，如果服务器端对请求数据的验证和处理不当，仍然可能存在安全漏洞。

4. 缓存性
+ GET
    + 具有可缓存性。浏览器通常会缓存 GET 请求的结果，当再次发起相同的 GET 请求时，如果缓存未过期，浏览器会直接从缓存中读取数据，而不会再次向服务器发送请求，这样可以提高页面的加载速度，减少服务器的负载。
+ POST
    + 一般不会被缓存。因为 POST 请求通常用于提交数据并可能对服务器资源产生改变，每次请求的结果可能不同，所以浏览器不会缓存 POST 请求的结果。

### 35. http和rpc区别

HTTP（超文本传输协议）和 RPC（远程过程调用）都是用于在不同系统或组件之间进行通信的机制，但它们在多个方面存在显著区别，下面为你详细介绍：

1. 设计目标
+ HTTP
    + 最初设计用于在 Web 浏览器和 Web 服务器之间传输超文本（如 HTML 页面），是一种通用的、无状态的应用层协议。它的目标是提供一种简单、灵活的方式来传输各种类型的数据，支持不同平台和技术栈之间的通信，具有良好的开放性和互操作性。
+ RPC
    + 主要用于实现不同进程或不同计算机之间的远程过程调用，让调用远程函数就像调用本地函数一样方便。其设计目标是简化分布式系统的开发，提高开发效率，使得开发者可以忽略底层网络通信的细节，专注于业务逻辑的实现。


2. 协议层面
+ HTTP
    + 是基于 TCP/IP 协议栈的应用层协议，使用标准的请求 - 响应模型。客户端发送 HTTP 请求，服务器接收请求并返回 HTTP 响应。HTTP 协议有明确的请求方法（如 GET、POST、PUT、DELETE 等）和状态码，用于表示请求的类型和处理结果。
    + HTTP 协议是文本协议，请求和响应的消息体通常以明文形式传输，易于理解和调试，但在传输效率上可能相对较低。
+ RPC
    + 可以基于多种传输协议实现，如 TCP、UDP 或 HTTP。RPC 没有统一的标准协议，不同的 RPC 框架可能有不同的协议实现。例如，gRPC 基于 HTTP/2 协议，Thrift 可以使用自定义的二进制协议。
    + RPC 协议通常是二进制协议，数据在传输前会进行序列化，以提高传输效率和减少带宽消耗。



### 36. http和websocket区别

### 37. static变量的初始化和线程安全

### 38. C和C++函数调用方式,CPP相比c的调用有哪些?

### 39. c++内存分区,堆区能否多线程共享


### 40. 如果一个类内存很大,给别人使用这个类时,怎么要求只能把内存分配到堆区>

### 41. 一块内存如果还没有被初始化就被其他线程访问会有问题吗?

### 42. 怎么写一个悲观锁?

### 43. SQL注入

### 44. git merge 和 get rebase的区别

git merge
+ git merge 会将多个分支的修改合并到当前分支，它会创建一个新的合并提交（merge commit）。这个合并提交有两个父提交，分别指向被合并的两个分支的最新提交，以此来表示此次合并操作整合了这两个分支的修改内容。
+ 例如，在 master 分支上执行 git merge feature，Git 会找到两个分支的共同祖先（即分叉点），然后将 feature 分支和 master 分支从共同祖先开始的修改内容进行合并，最后生成一个新的合并提交添加到 master 分支上。

git rebase
+ git rebase 是将一个分支的修改逐个应用到另一个分支上。它会把当前分支的提交从原来的基础上分离出来，然后在目标分支的最新提交后面依次重新应用这些提交，让提交历史看起来就像是在目标分支的基础上依次进行开发一样，不会产生额外的合并提交。
+ 例如，在 feature 分支上执行 git rebase master，Git 会找到 feature 分支和 master 分支的共同祖先，然后将 feature 分支上从共同祖先之后的所有提交暂时保存起来，接着将 feature 分支的指针移动到 master 分支的最新提交上，最后再把之前保存的提交依次应用到 feature 分支上。

历史记录呈现
git merge
+ 使用 git merge 会保留分支的分叉历史，在查看提交历史时可以清晰地看到各个分支的发展路径以及合并操作的痕迹。合并提交会在历史记录中形成一个分叉点，显示出不同分支的修改是如何合并在一起的。
+ 这种历史记录可以直观地反映出团队成员的开发过程和分支之间的关系，但如果频繁进行合并操作，提交历史可能会变得比较复杂和混乱。
git rebase
+ git rebase 会使提交历史变得更加线性，看起来就像是所有的开发工作都是在一条直线上依次进行的。它消除了分支分叉的情况，让提交历史更加简洁、清晰。
+ 这种线性的提交历史便于查看和理解，也有助于后续的代码审查和版本回溯，但它掩盖了实际的开发分支情况。







