# CMU15445 1

## LRU是怎么实现的，什么是 LRU-K ？

LRU-K 算法**驱逐向后 k 距离最大的帧**。向后 k 距离计算为 当前时间戳与第 k 次之前访问的时间戳之间的差。对于历史访问少于 k 次的帧，其向后 k 距离为 +inf。当多个帧的向后 k 距离为 +inf 时，替换器将驱逐整体时间戳最早的帧（即记录访问时间最久的帧）。

> k怎么选择？依据

访问频率：如果数据的访问频率非常高且分布均匀，较小的K值（如K=1或K=2）可能就足够了。较大的K值可能会引入不必要的复杂性和开销。
访问间隔：如果数据的访问间隔较长且不规律，较大的K值（如K=5或K=10）可能更合适，因为它们可以更好地捕捉长期的访问模式。

## LRU-K 的优势？

存在两个用户，一个用户需要进行一次扫描操作，而另一个用户进行正常的随机访问操作。扫描操作其实很简单，例如遍历一张数据表等，但其带来的后果却是灾难的。扫描操作会快速引用大量页面，这对于传统 LRU 而言将迅速驱逐所有随机访问页面，但是扫描操作引用的页面几乎在之后很长一段时间内不再被引用，而随机访问页面才是真正需要被缓存的，这几乎使传统的 LRU 失效。


## 既然考虑频率为什么不采用 LFU？

+ LFU 只考虑频率，而实际最近访问时间依然是一个重要因素。
+ LFU 过渡考虑频率，带来的开销巨大，它是这么做的：考虑最近T 秒内，页面访问的次数。这将记录最近 T 分钟内的所有访问，如果页面访问次数非常频繁，带来的开销就是极其巨大的。

LRU-K：它更能应对突发流量，避免因短时间内大量访问某些项而导致其他重要项被错误地替换掉。
LFU 算法基于每个项的访问频率，但在突发流量的情况下，可能会导致一些高频但不重要的项占据缓存空间，从而影响缓存的整体性能。

LRU-K 可以更准确地判断哪些项是真正重要的，从而提高缓存命中率。
LFU：虽然 LFU 也能提高命中率，但在某些情况下，它可能会过于依赖频率计数，而忽略了一些近期频繁访问但未来可能不再重要的项。

总而言之，LFU 适合**访问频率低**的场景，LRU **适合高速**访问场景。


## BPM 里有用到什么吗？

磁盘调度器，其实就是实现一个消息队列。并在维护一个线程来处理读写请求；

维护一个 pages，Page 对象只是缓冲池中内存的容器，用来装page的信息，
维护一个 空闲桢，空闲桢用来page_id和数组下标的映射，因为lru_k替换策略其实就是维护下标；
还有一个页表：空闲桢和page_id的映射；

创建一个page：先从空闲桢中拿到一个桢，如果没有则用lru_k替换策略删除，如果有脏页则写回。
flush刷新到磁盘；


磁盘管理器怎么读写？
创建磁盘掉管理器时，会传入一个 file文件，用来读写；
后面的操作都是在这个文件是进行操作的，
比如说：read要传入 page_id,和*page_data,根据page_id可计算出偏移量。然后利用seekp(offset)找到位置，如果读取的数量小于 pagesize则填充0；


## 可拓展哈希表为什么要三层分页？

三层分页中，分为 Header Page / Directory Page / Bucket Page，其中前两层分页用于索引，第三层分页用于实际存储键值对。

为什么要分页？ 
首先可以减少外部碎片化，提升了内存的利用率；

分页这个东西，其实可以理解一个位置信息，可以快速的定位这个数据在哪一块。假如不分页，就需要遍历全部的数据来找到想要的数据；
分页的话，就可以先找到这个数据在哪一块，然后再在这一块中寻找。
假如总数据大小为4096*10,及10页，想找到数据就要读取10页；而分页的话就只需要读取一页了；

因为我们存储的元素是key,value；value其实就是tuple所处的位置，他们都是存放在页中的。

为什么二级分页不行？ 
准确来说，不是二级分页不行，而是二级分页不好。首先，三级分页相比二级分页有更大的存储空间，如果页大小是 4096B，那么三级分页大概可以存储 1e9 的数据规模，而二级分页大概为 1e6 的数据规模。另外，三级分页相对于二级分页有更多**并发性能提升空间**，因为在下级分页可以释放上级分页持有的锁；但分页过多会产生页面命中不集中的问题，这需要 Grow/Shrink 机制来实现。

Grow/Shrink 机制如何解决命中率下降问题？ 
通过在一些级别的页中增加 Grow/Shrink 机制可以很好的提高命中率，在我们的三级分页中，只在 Directory 页使用了 Grow/Shrink 机制，Header 没有使用。

​实现原理： 事实上在这个机制下，这个 Directory 页下的所有索引都指向相同的 Bucket，当这个 Bucket 满时，它会进行 Grow，这需要重新计算哈希值来将原本桶中的键值对分到两个桶中。而在一个桶为空时，它将尝试进行 Shrink，这将导致两个桶合并，而 Directory 中的索引也会重新指向相同的桶。但这个过程会带来并发效率的降低。

​为什么解决了问题？ 
这样做使用了更少的桶，准确来说，在刚开始一个 Directory 下只管理了一个 Bucket，在数据量少时这样一个 Bucket 就已经足够了。桶的数量会随着数据规模的增长而增长，而桶的数量对于页的数量是起到决定性作用的。

为什么并发效率降低了？为什么不给 Header 使用 Grow/Shrink 机制？ Grow/Shrink 机制减少了页的数量，但与此同时，我们发现 Grow 操作需要同时持有三个页的锁（一个 Directory、两个 Bucket，当然我们也可以先完成所有 Directory 内的操作然后释放它）。总之它会更长时间的占用更高级别的公共资源，并发效率就会下降。也正是因为占用高级别公共资源对并发效率影响巨大，因此对 Header 添加 Grow/Shrink 机制可能带来负面效果；如果对 Header 添加这个机制，那么每次索引都一定花费额外的时间保证该机制的工作，重点是这个过程是持锁的，而在 Directory 持有同一锁的概率是 
1/1000。

​为什么维护 Grow/Shrink 的数据保存在 Directory 中，而非各个 Bucket 中？ 
这个操作在进行 Shrink 的时候，检测到一个桶空，就无需去打开另非空桶去修改它的值，这减少了换页的可能性。


为什么不采用更多级分页？
使用更多级分页的唯一理由是希望存储更大规模是数据，因为多级索引或带来额外的索引开销。如果确实需要增加级数，那么我依然建议在第一级不使用 Grow/Shrink 机制，而在后面的中间所有的分级中使用这一机制，这样可以很好的权衡并发效率和页的命中率。


## 比较哈希表和 B+ 树。



## 哈希表的区间索引是怎么做的？

哈希索引无法进行范围查找。对于哈希索引，进行范围查找必须扫描表。

对比 B+ 树索引和哈希索引。

哈希索引具有更好的性能和并发效率。 修改性能方面：哈希索引进行的维护操作更加简单，因此具有更好的性能。查找性能方面：哈希索引直接计算哈希值，并逐级索引即可；而 B+ 树需要在节点中遍历或二分。并发效率方面：B+ 树为保证并发安全，必须持有整条链路的锁，而哈希索引则可以提前释放锁。B+ 树索引的优势在于，B+ 树索引可以进行区间查找，无需排序等。

B+ 树在区间索引、排序、分组方面表现远优于哈希索引。 哈希索引只支持快速的等值查找，在区间索引方面，与没有适用索引几乎别无二致。B+ 树具有顺序性，在区间索引方面与等值查找效率相仿。


为什么 B+ 树索引更常用？ 
前面讲到在等值查找和修改方面，哈希索引的性能优于 B+ 树，但这个优势是有限的，是一个常数倍的优势。而在区间索引方面，这个差异在时间复杂度上是天差地别的。最后，区间索引是数据库中十分常见的操作，这个操作必须被重要考虑。



