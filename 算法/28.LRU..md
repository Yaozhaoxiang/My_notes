# leetcode 146

LRU (Least Recently Used) 是一种常用的缓存淘汰算法，用于管理有限的内存资源。当缓存满了，而又有新的数据需要加入时，LRU 算法会选择最近最少使用的数据项进行淘汰，以腾出空间。这里的“最近最少使用”指的是在最近的一段时间内没有被访问过的数据项。

LRU 的实现
 1. 数据结构：通常使用一个双向链表（或双向链表结合哈希表）来实现 LRU 缓存。
  + 双向链表用于维护数据项的访问顺序。
  + 哈希表用于快速定位链表中的节点。
 2. 操作流程：
  + 插入：当有新数据项需要插入时，如果缓存已满，则先淘汰链表尾部的数据项，然后在链表头部插入新数据项。
  + 访问：当访问一个数据项时，如果数据项在链表中，将其移到链表头部；如果不在，则插入到链表头部，并在必要时淘汰尾部的数据项。 


请你设计并实现一个满足  LRU (最近最少使用) 缓存 约束的数据结构。
实现 LRUCache 类：
  + LRUCache(int capacity) 以 正整数 作为容量 capacity 初始化 LRU 缓存
  + int get(int key) 如果关键字 key 存在于缓存中，则返回关键字的值，否则返回 -1 。
  + void put(int key, int value) 如果关键字 key 已经存在，则变更其数据值 value ；如果不存在，则向缓存中插入该组 key-value 。如果插入操作导致关键字数量超过 capacity ，则应该 逐出 最久未使用的关键字。
函数 get 和 put 必须以 O(1) 的平均时间复杂度运行。

## 1.  unordered_map + list 
具体思路如下：
  使用 unordered_map 来快速查找缓存中的键值对。键为缓存的 key，值为指向双向链表中对应元素的迭代器（指向的元素存储的是 key 和 value）。

  使用 list 来存储缓存中的元素，并且确保最新使用的元素在链表头部，最久未使用的元素在链表尾部。这样，当缓存超过容量时，可以直接从链表尾部删除元素。

```cpp
class LRUCache {
public:
    LRUCache(int capacity) : capacity_(capacity) {}

    int get(int key) {
        auto it = cache_map_.find(key);
        if (it == cache_map_.end()) {
            return -1;  // 如果 key 不存在，返回 -1
        }
        // 如果 key 存在，将其移动到链表头部（表示最近使用）
        cache_list_.splice(cache_list_.begin(), cache_list_, it->second);
        return it->second->second;
    }

    void put(int key, int value) {
        auto it = cache_map_.find(key);
        if (it != cache_map_.end()) {
            // 如果 key 已经存在，更新 value，并将其移动到链表头部
            cache_list_.splice(cache_list_.begin(), cache_list_, it->second);
            it->second->second = value;
        } else {
            // 如果 key 不存在，插入新的键值对
            if (cache_list_.size() == capacity_) {
                // 如果缓存已满，移除链表尾部元素（最久未使用的）
                int old_key = cache_list_.back().first;
                cache_list_.pop_back();
                cache_map_.erase(old_key);
            }
            // 将新的键值对插入到链表头部
            cache_list_.emplace_front(key, value);
            cache_map_[key] = cache_list_.begin();
        }
    }

private:
    int capacity_;  // 缓存容量
    std::list<std::pair<int, int>> cache_list_;  // 存储键值对的双向链表
    std::unordered_map<int, std::list<std::pair<int, int>>::iterator> cache_map_;  // 哈希表，key 对应链表迭代器
};
```

### 1.1 带过期时间的LRU

```c++
#include <unordered_map>
#include <list>
#include <chrono>

class LRUCacheWithTTL {
public:
    using Clock = std::chrono::steady_clock;
    using TimePoint = Clock::time_point;

    LRUCacheWithTTL(int capacity) : capacity_(capacity) {}

    int get(int key) {
        auto it = cache_map_.find(key);
        if (it == cache_map_.end()) {
            return -1;
        }
        auto node_it = it->second;
        if (Clock::now() >= node_it->expire_time) {
            // 已过期，移除
            cache_list_.erase(node_it);
            cache_map_.erase(it);
            return -1;
        }
        // 移到链表头部
        cache_list_.splice(cache_list_.begin(), cache_list_, node_it);
        return node_it->value;
    }

    void put(int key, int value, int ttl_seconds) {
        auto now = Clock::now();
        auto expire = now + std::chrono::seconds(ttl_seconds);

        auto it = cache_map_.find(key);
        if (it != cache_map_.end()) {
            auto node_it = it->second;
            node_it->value = value;
            node_it->expire_time = expire;
            cache_list_.splice(cache_list_.begin(), cache_list_, node_it);
        } else {
            // 清除过期项（可选，懒惰清理）
            clean_expired();

            if (cache_list_.size() >= capacity_) {
                // 移除最久未使用的
                auto back_it = cache_list_.rbegin();
                cache_map_.erase(back_it->key);
                cache_list_.pop_back();
            }
            cache_list_.emplace_front(CacheNode{key, value, expire});
            cache_map_[key] = cache_list_.begin();
        }
    }

private:
    struct CacheNode {
        int key;
        int value;
        TimePoint expire_time;
    };

    void clean_expired() {
        for (auto it = cache_list_.rbegin(); it != cache_list_.rend(); ) {
            if (Clock::now() >= it->expire_time) {
                cache_map_.erase(it->key);
                // reverse_iterator 转为 base() 再 -- 得到正确正向迭代器
                cache_list_.erase(std::next(it).base());
                it = cache_list_.rbegin(); // restart from back
            } else {
                ++it;
            }
        }
    }

    int capacity_;
    std::list<CacheNode> cache_list_;
    std::unordered_map<int, std::list<CacheNode>::iterator> cache_map_;
};
int main() {
    std::cout << "测试带过期时间的LRUCache:\n";
    LRUCacheWithTTL cache(2);

    std::cout << "Put(1, 100, 2秒)\n";
    cache.put(1, 100, 2);
    std::cout << "Get(1): " << cache.get(1) << "（应该是100）\n";

    std::this_thread::sleep_for(std::chrono::seconds(3));
    std::cout << "3秒后 Get(1): " << cache.get(1) << "（应该是-1，已过期）\n";

    std::cout << "Put(2, 200, 5秒)\n";
    cache.put(2, 200, 5);
    std::cout << "Put(3, 300, 5秒)\n";
    cache.put(3, 300, 5);  // 此时应触发容量限制，逐出旧的（key=2）

    std::cout << "Get(2): " << cache.get(2) << "（可能是-1，因为被淘汰）\n";
    std::cout << "Get(3): " << cache.get(3) << "（应该是300）\n";

    std::cout << "Put(4, 400, 1秒)\n";
    cache.put(4, 400, 1);

    std::this_thread::sleep_for(std::chrono::seconds(2));
    std::cout << "2秒后 Get(4): " << cache.get(4) << "（应该是-1）\n";

    return 0;
}
```


## 2. 自定义 node
在双向链表的实现中，使用一个伪头部（dummy head）和伪尾部（dummy tail）标记界限，这样在添加节点和删除节点的时候就不需要检查相邻的节点是否存在。
```cpp
struct DLinkedNode {
    int key, value;
    DLinkedNode* prev;
    DLinkedNode* next;
    DLinkedNode(): key(0), value(0), prev(nullptr), next(nullptr) {}
    DLinkedNode(int _key, int _value): key(_key), value(_value), prev(nullptr), next(nullptr) {}
};

class LRUCache {
private:
    unordered_map<int, DLinkedNode*> cache;
    DLinkedNode* head;
    DLinkedNode* tail;
    int size;
    int capacity;

public:
    LRUCache(int _capacity): capacity(_capacity), size(0) {
        // 使用伪头部和伪尾部节点
        head = new DLinkedNode();
        tail = new DLinkedNode();
        head->next = tail;
        tail->prev = head;
    }
    
    int get(int key) {
        if (!cache.count(key)) {
            return -1;
        }
        // 如果 key 存在，先通过哈希表定位，再移到头部
        DLinkedNode* node = cache[key];
        moveToHead(node);
        return node->value;
    }
    
    void put(int key, int value) {
        if (!cache.count(key)) {
            // 如果 key 不存在，创建一个新的节点
            DLinkedNode* node = new DLinkedNode(key, value);
            // 添加进哈希表
            cache[key] = node;
            // 添加至双向链表的头部
            addToHead(node);
            ++size;
            if (size > capacity) {
                // 如果超出容量，删除双向链表的尾部节点
                DLinkedNode* removed = removeTail();
                // 删除哈希表中对应的项
                cache.erase(removed->key);
                // 防止内存泄漏
                delete removed;
                --size;
            }
        }
        else {
            // 如果 key 存在，先通过哈希表定位，再修改 value，并移到头部
            DLinkedNode* node = cache[key];
            node->value = value;
            moveToHead(node);
        }
    }

    void addToHead(DLinkedNode* node) {
        node->prev = head;
        node->next = head->next;
        head->next->prev = node;
        head->next = node;
    }
    
    void removeNode(DLinkedNode* node) {
        node->prev->next = node->next;
        node->next->prev = node->prev;
    }

    void moveToHead(DLinkedNode* node) {
        removeNode(node);
        addToHead(node);
    }

    DLinkedNode* removeTail() {
        DLinkedNode* node = tail->prev;
        removeNode(node);
        return node;
    }
};

作者：力扣官方题解
链接：https://leetcode.cn/problems/lru-cache/solutions/259678/lruhuan-cun-ji-zhi-by-leetcode-solution/
来源：力扣（LeetCode）
著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。
```

# LRU-K
LRU-k 是 LRU 算法的一种扩展，它考虑了最近 k 次的访问记录。也就是说，LRU-k 算法在淘汰数据项时不仅仅考虑最近一次的访问记录，而是考虑最近 k 次的访问记录。

LRU-k 的实现
LRU-k 的实现比 LRU 更复杂，因为它需要跟踪每个数据项的最近 k 次访问记录。常见的实现方法包括：
 1. 多级索引：使用多个索引来跟踪每个数据项的最近 k 次访问记录。例如，可以使用 k 个链表，每个链表代表不同的访问频率等级。
 2. 计数器：为每个数据项增加一个计数器，记录其最近 k 次的访问次数。每次访问时，更新计数器，并根据计数器的值来调整数据项的位置。
 3. 访问序列：维护一个访问序列，记录每个数据项的最近 k 次访问时间戳。每次访问时，更新访问序列，并根据时间戳来调整数据项的位置。

LRU-k 算法通过引入一个额外的访问历史队列来记录数据的访问次数。只有当数据的访问次数达到 k 次时，才会将其加入到缓存队列中。这样做的目的是确保只有那些被频繁访问的数据才会被保留在缓存中，从而减少缓存污染的影响。

LRU-k 的实现通常包括以下几个关键组件：
 1. 历史队列：用于记录数据的访问次数。只有当数据的访问次数达到 k 次时，才会将其从历史队列中移出并加入到缓存队列中。
 2. 缓存队列：用于存储已经被确认为高频访问的数据。

操作流程
 1. 数据访问：
  + 当数据第一次被访问时，将其加入到历史队列中。
  + 每次访问历史队列中的数据时，更新其访问次数。
  + 当数据的访问次数达到 k 次时，将其从历史队列中移出并加入到缓存队列中。
 2. 缓存淘汰：
  + 当缓存队列满时，需要淘汰缓存队列中最近 k 次访问时间距当前时间最大的数据。
  + 如果有多个数据的 k 距离相同，可以选择最近最少使用的数据进行淘汰。

```cpp
#include <list>
#include <unordered_map>
#include <unordered_set>

template <typename K, typename V>
class LRUKCache {
public:
    LRUKCache(size_t capacity, int k)
        : _capacity(capacity), _k(k) {}

    void put(const K& key, const V& value) {
        std::lock_guard<std::mutex> lock(_mutex);

        auto it = _cache.find(key);
        if (it != _cache.end()) {
            // 更新缓存中的数据
            _lru.splice(_lru.begin(), _lru, it->second);
            it->second->second = value;
            return;
        }

        if (_cache.size() >= _capacity) {
            // 淘汰缓存队列中最旧的数据
            K lruKey = _lru.back().first;
            _cache.erase(lruKey);
            _lru.pop_back();
        }

        // 将新数据加入到历史队列
        _history[key] = 1;
        if (_history[key] == _k) {
            // 达到k次访问，移入缓存队列
            _lru.push_front({key, value});
            _cache[key] = _lru.begin();
            _history.erase(key);
        }
    }

    V get(const K& key) {
        std::lock_guard<std::mutex> lock(_mutex);

        auto it = _cache.find(key);
        if (it == _cache.end()) {
            return V(); // 返回默认值
        }

        // 更新缓存中的数据
        _lru.splice(_lru.begin(), _lru, it->second);
        return it->second->second;
    }

private:
    size_t _capacity;
    int _k;
    std::list<std::pair<K, V>> _lru; // 缓存队列
    std::unordered_map<K, std::list<std::pair<K, V>>::iterator> _cache; // 缓存索引
    
    std::unordered_map<K, int> _history; // 访问历史记录
    std::mutex _mutex;
};
```









