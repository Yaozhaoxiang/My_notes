项目描述：busTub是一个使用C++实现的关系行数据库管理系统，支持基本的sql，bustub涵盖了内存管理、索引、优化器、
执行器以及snapshot隔离级别的并发控制。

主要工作：
• 实现了基于LRU-K的缓冲池：缓冲池负责将物理页面在主内存和磁盘之间来回移动，缓冲池采用LRU-K算法淘汰数据
页，使用RAII封装数据页的读写接口。实现磁盘调度器组件，维护一个后台线程实现磁盘与缓冲池之间的数据读写。
• 实现了基于可扩展哈希表的哈希索引：支持并发的索引查找和插入操作。
• 实现了火山模型查询引擎的常用算子：如seqscan、indexscan、insert、delete、update 等，实现 JOIN 连接、聚集函数，
ORDERBY+LIMIT的算子、窗口函数。修改了bustub的基于规则的优化器，添加了seqscan到indexscan的优化规则、嵌
套循环连接转换为哈希连接的优化规则、采用堆实现Top-N的优化规则。
• 基于MVCC实现并发控制：隔离级别为snapshot，为事务和tuple添加时间戳进行并发控制和写-写冲突的检查，修改了
insert、delete、update 算子实现 tuple 的原地更新，并且在事务的内存空间里面存储了旧版本的tuple，添加垃圾回收机制
回收无用的历史tuple版本。


## 1 实现了基于LRU-K的缓冲池
为什么要有 Buffer pool
  + Buffer pool有多大？
  + Buffer pool缓存什么？

如何管理 Buffer pool
 + 如果管理空闲页？
 + 如何管理脏页？
 + 如何提高缓存命中率？
 + 脏页什么时候被刷入磁盘

怎么写到磁盘中？
打开一个数据库文件时，会分配一个磁盘调度器，初始化的时候会打开这个文件流；
当要写入page时，会先计算偏移量，pagesize*page_id;
然后写入；



缓冲池负责将物理页面在主内存和磁盘之间来回移动，缓冲池采用LRU-K算法淘汰数据页，使用RAII封装数据页的读写接口。实现磁盘调度器组件，维护一个后台线程实现磁盘与缓冲池之间的数据读写。

首先第一部分：为数据库管理构建一个面向磁盘的存储管理器，也就是实现一个缓冲池，它的作用就是将物理页面在内存和磁盘之间来回切换。这样就会使得数据库管理系统能够支持比系统可用内存更大的数据库。缓冲池的操作对其他部分是透明的。例如，系统通过一个唯一的 page_id向缓冲池请求页面，而无需知道该页面是否已经在内存中，或者系统是否需要从磁盘检索它。

主要实现以下存储管理器组件：

+ LRU-K 替换策略
+ 磁盘调度程序
+ 缓冲池管理器

### 1. LRU-K 替换策略
该组件负责跟踪缓冲池中的页面使用情况。当我们需要从缓冲池中替换一个页面的时候，通过LRU-K来选择删除的页面。

为什么使用LRU-K
普通的LRU，也就是LRU-1是删除未使用页面最久的哪个页面，但是这是不合理的，因为这回忽略页面的访问频率，容易受到顺序扫描，比如说一个页面是使用了50次了，这个时候我们需要遍历一个数据，但是这个数据很大，当遍历的时候，我们就可能替换掉这个曾经经常访问的数据，这是不合理的。所以才使用LRU-K这个替换策略。

LRU-K原理
跟踪每个页面最后K次引用的历史作为时间戳，并计算连续访问之间的间隔。这个距离怎么算的呢？当前时间戳与第 k 次之前访问的时间戳之间的差；对于历史访问少于 k 次的帧，其向后 k 距离为 +inf。当多个帧的向后 k 距离为 +inf 时，替换器将驱逐整体时间戳最早的帧（即记录访问时间最久的帧）。

怎么实现的：
因为维护的是帧，所以定义一个 LRUNode，这里面保存一个history数组，它的大小就是k，当访问过一次，就把当前的时间戳从后向前加到这个数组中。也就是说history数组的前面就是第k次访问的时间戳，这个值越小，也就意味着离当前越久，则先删除这个。用两个链表维护，一个是访问次数小于k的，一个大于k；


### 2. 磁盘调度程序
这个组件负责在 DiskManager 上调度读写操作，当上层请求读或者写一个页面时，会生成一个请求对象。调度器维护一个后台工作线程，该线程使用磁盘管理器处理已调度的请求。

盘调度器将利用一个**共享队列**来**调度和处理 DiskRequest**。一个线程将向队列添加请求，而磁盘调度器的后台工作线程将处理排队的请求。


### 3. 缓冲池管理器
缓冲池管理器负责通过 DiskScheduler 从磁盘获取数据库页面并将其存储在内存中。

内存页面是由page对象表示的。这个page是什么呢？
 Page 对象只是缓冲池中内存的容器，因此并不特定于某一唯一页面。也就是说，每个 Page 对象包含一块内存，DiskManager 将使用该内存位置来复制从磁盘读取的物理页面的内容。缓冲池管理器会重用相同的 Page 对象来存储数据，因为它在磁盘与内存之间来回移动。这意味着同一个 Page 对象在系统生命周期内可能包含不同的物理页面。Page 对象的标识符（page_id）用于跟踪其包含的物理页面；如果 Page 对象不包含物理页面，则其 page_id 必须设置为 INVALID_PAGE_ID。









##  实现了基于可扩展哈希表的哈希索引：
支持并发的索引查找和插入操作。

通过一个hash索引来寻找：
该哈希表分为三个层：头页面，目录页面，桶页面；
头页面用来索引目录页面，目录页面用来索引桶，桶里面保存的就是key，val；

在头页面中有一个最大索引深度 max_depth, 这是根据 hash的最高max_depth_位进行索引。通过这个索引找到目录页的页面号，通过这个page_id就可以得到目录页；

每个目录页面存储指向桶页面的逻辑子指针（作为页面 ID），以及处理桶映射和动态目录扩展与收缩的元数据。通过hash的最低 global_depth_位，找到桶索引，从而找到桶page_id;

桶页面位于基于磁盘的可扩展哈希表的第三层。它们实际存储键值对。

关于插入：
当桶满的时候，那么这个桶就需要分成两个桶；把桶的深度加1，然后重新分配tuple；
桶合并
当桶变为空时必须尝试合并。可以通过检查桶及其分裂图像的占用情况来更积极地合并，但是这些昂贵的检查和额外的合并可能会增加冲突。

### 补充 b+树
磁盘结构：
每个磁盘被划分一个个磁道，每个磁道又划分为一个个扇区，每个扇区就是以”磁盘块“。各个扇区存放的数据量相同，所以最内层磁道上的扇区数据密度最大。
可用（柱面号，盘面号，扇区号）来定位任意一个“磁盘块”；
我们经常提到文件数据存放在外存中的几号块（逻辑地址），这个块号就可以转换成（柱面号，盘面号，扇区号）的地址形式。
每一个块大小通常是 512个字节，每个字节都有他自己的地址

磁盘上的数据，需要通过ram来进行读取和写给程序使用；

假如没有所以，我们就必须扫描磁盘上的数据，找到我们想要的数据；在磁盘上是通过页保存的，那么我们就可以通过记录每个数据的位置信息，通过这个位置信息找到数据，这就加快了访问，比如：page_id,slot_num_；

index就是加快访问的，通过记录每个数据在磁盘上的位置信息，位置信息占用的块很少，因为只维护了 rid，所以我们从磁盘中读取的消耗就很小；比如说原始数据在磁盘上占用 100 0000个块，可能索引只占用 10000个块，从磁盘中访问10000个块肯定比100 0000个块块。那么如果是多级索引呢？那么就是再将 10000/100=100，通过访问100+1就可以找到原始信息了，更快了；

b树只是m叉搜索树加上一些规则，
 + 树中每个结点至多有m棵子树；
 + 若根节点不是叶子节点，则至少有两个子树
 + 除根之外的所有非中断节点至少有 m/2 棵子树
 + 所有的非终端节点中包含下列信息数据：(n,A0,K1,A1,K2...Kn,An)
 + 所有的叶子节点都会出现在同一层次上，并且不带信息（可以看作是外部结点或查找失败的节点，实际上这些节点不存在，指向这些节点的指针为空）
 + 从低向上建立

b树中每个节点键值key都有一个val；这个val就是要保存的数据，因为每一个节点都保存数据，就导致每一个节点保存的信息很少，比如说每一个data 1k字节，假如不考虑指针大小，则每个节点只保存16个个信息。
这就是它的缺点，而b+树解决了这个问题，b+树只保存指针和键值信息，并不保存数据，把数据信息全部保存到叶子节点。

B+树和B树类似，但多了几条规则
+ 非叶子结点的子树指针个数与关键字（节点中的元素个数）个数相同
+ 非叶子结点的子树指针P[i]，指向关键字值属于[K[i], K[i+1])的子树（B-树是开区间）
+ 所有叶子结点有一个链指针
+ 所有关键字都在叶子结点出现
+ 只有叶子节点有Data域


### b+树与哈希

1、在查询速度上，如果是等值查询，那么Hash索引明显有绝对优势，因为只需要经过一次 Hash 算法即可找到相应的键值，复杂度为O(1)；当然了，这个前提是键值都是唯一的。如果键值不是唯一(或存在Hash冲突)，就需要先找到该键所在位置，然后再根据链表往后扫描，直到找到相应的数据，这时候复杂度会变成O(n)，降低了Hash索引的查找效率。所以，Hash 索引通常不会用到重复值多的列上，比如列为性别、年龄的情况等（当然B+tree索引也不适合这种离散型低的字段上）；

2、Hash 索引是无序的，如果是范围查询检索，这时候 Hash 索引就无法起到作用，即使原先是有序的键值，经过 Hash 算法后，也会变成不连续的了。因此
 + Hash 索引只支持等值比较查询、无法索成范围查询检索，B+tree索引的叶子节点形成有序链表，便于范围查询。

 + Hash 索引无法做 like ‘xxx%’ 这样的部分模糊查询，因为需要对 完整 key 做 Hash 计算，定位bucket。而 B+tree 索引具有最左前缀匹配，可以进行部分模糊查询。

 + Hash索引中存放的是经过Hash计算之后的Hash值，而且Hash值的大小关系并不一定和Hash运算前的键值完全一样，所以数据库无法利用索引的数据来避免任何排序运算。B+tree 索引的叶子节点形成有序链表，可用于排序。

3、Hash 索引不支持多列联合索引，对于联合索引来说，Hash 索引在计算 Hash 值的时候是将索引键合并后再一起计算 Hash 值，不会针对每个索引单独计算 Hash 值。因此如果用到联合索引的一个或者几个索引时，联合索引无法被利用；

4、因为存在哈希碰撞问题，在有大量重复键值情况下，哈希索引的效率极低。B+tree 所有查询都要找到叶子节点，性能稳定；


## 实现了火山模型查询引擎的常用算子：
如seqscan、indexscan、insert、delete、update 等，实现 JOIN 连接、聚集函数，ORDERBY+LIMIT的算子、窗口函数。修改了bustub的基于规则的优化器，添加了seqscan到indexscan的优化规则、嵌套循环连接转换为哈希连接的优化规则、采用堆实现Top-N的优化规则。

1. 什么是火山模型
  每个算子都有 Init() 和 Next() 两个方法。Init() 对算子进行初始化工作。Next() 则是向下层算子请求下一条数据。当 Next() 返回 false 时，则代表下层算子已经没有剩余数据，迭代结束。可以看到，火山模型一次调用请求一条数据，占用内存较小，但函数调用开销大，特别是虚函数调用造成 cache miss 等问题。
2. 怎么实现这些算子的，介绍一下


3. 添加了哪些优化规则
 + Optimizing SeqScan to IndexScan：优化规则：PlanNode具有Expression，其类型为比较表达式。且Expression的一个子表达式类型为列值表达式，另一个子表达式的类型为常量表达式，且列值表达式所表示的列上具有索引。此时SeqScan可以被转换成IndexScan。
 + 将嵌套循环连接优化为哈希连接，嵌套循环就是把外表的每一条和内表的每一条进行匹配。哈希连接通常比嵌套循环连接提供更好的性能。你应该修改优化器，当可以使用哈希连接时，将 NestedLoopJoinPlanNode 转换为 HashJoinPlanNode。具体来说，**当连接谓词是由多个等值条件构成的合取时，可以使用哈希连接算法**。对于此项目，你应该能够处理由 AND 连接的任意数量的等值条件。哈希链接其实就是，构建一个哈希表，然后把左表全部映射到哈希表中，然后遍历右表，找到相同的表进行匹配。
+ 
 + 堆实现Top-N的优化规则：（1）对表中的所有数据进行排序；（2）获取前 10 个元素。这显然是低效的，因为查询只需要最小的值。一种更聪明的方法是动态跟踪目前为止最小的 10 个元素。这就是 BusTub 的 TopNExecutor 所做的。利用std::priority_queue


4. 怎么实现的聚合函数；
 + 它恰好有一个子节点。输出模式由分组列后跟聚合列组成。
 + 实现聚合的一个常见策略是使用哈希表，其中分组列为键。
 + 把每个tuple换成key，key是根据group_by的列来实现的，插入到哈希表中

5. 怎么实现join的
 + 简单嵌套循环连接算法来实现 NestedLoopJoinExecutor 的内连接和左连接
 + 遍历左表和右表进行匹配

6. 窗口函数：，窗口函数有三个部分：**按分区(partition by)、按顺序(order by)和窗口帧(window frames)**


ORDERBY+LIMIT的算子、窗口函数 采用堆实现Top-N的优化规则。




## 基于MVCC实现并发控制：隔离级别为snapshot，
为事务和tuple添加时间戳进行并发控制和写-写冲突的检查，修改了insert、delete、update 算子实现 tuple 的原地更新，并且在事务的内存空间里面存储了旧版本的tuple，添加垃圾回收机制回收无用的历史tuple版本。


1. 介绍一下mvcc 1
2. 什么是 snapshot 
3. 写写冲突 1
4. 怎么实现垃圾回收机制 1
5. 什么是事务 1



















